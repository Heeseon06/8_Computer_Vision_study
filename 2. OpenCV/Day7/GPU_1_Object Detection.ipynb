{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18af03d5-8f01-4a75-8a85-c5afddcc3603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available: True\n",
      "Number of available GPUs: 1\n",
      "Current GPU: NVIDIA GeForce RTX 4090\n",
      "GPU Memory Usage:\n",
      "Allocated: 0\n",
      "Cached: 0\n",
      "PyTorch is using: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# GPU 사용 가능 여부 확인\n",
    "print(f\"CUDA is available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# 사용 가능한 GPU 개수 확인\n",
    "print(f\"Number of available GPUs: {torch.cuda.device_count()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # 현재 사용 중인 GPU의 이름 확인\n",
    "    print(f\"Current GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    # 현재 GPU의 메모리 사용량 확인 (단위: bytes)\n",
    "    print(f\"GPU Memory Usage:\")\n",
    "    print(f\"Allocated: {torch.cuda.memory_allocated(0)}\")\n",
    "    print(f\"Cached: {torch.cuda.memory_reserved(0)}\")\n",
    "else:\n",
    "    print(\"GPU is not available. CPU will be used instead.\")\n",
    "\n",
    "# 현재 PyTorch가 사용하도록 설정된 장치 확인\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"PyTorch is using: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10bb8dbd-7e36-40d0-80ff-03083ee289cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from ipywidgets import interact\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torchvision.utils import make_grid\n",
    "from util import CLASS_NAME_TO_ID, CLASS_ID_TO_NAME, visualize, save_model\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from collections import defaultdict\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eae80117-6959-42eb-b219-bc10ef070a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './DataSet/'\n",
    "data_df = pd.read_csv(os.path.join(data_dir, 'df.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f33f68f4-9c90-4b19-bf53-a7e8a7f4c2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detection_dataset():\n",
    "    def __init__(self, data_dir, phase, transformer=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.phase = phase\n",
    "        self.data_df = pd.read_csv(os.path.join(self.data_dir, 'df.csv'))\n",
    "        self.image_files = [fn for fn in os.listdir(os.path.join(self.data_dir, phase)) if fn.endswith('jpg')]\n",
    "        self.transformer = transformer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filename, image = self.get_image(index)\n",
    "        bboxes, class_ids = self.get_label(filename)\n",
    "        img_H, img_W, _ = image.shape\n",
    "        if self.transformer:\n",
    "            image = self.transformer(image)\n",
    "            _, img_H, img_W = image.shape\n",
    "        bboxes[:, [0, 2]] *= img_W\n",
    "        bboxes[:, [1, 3]] *= img_H\n",
    "        target = {}\n",
    "        target['boxes'] = torch.Tensor(bboxes).float()\n",
    "        target['labels'] = torch.Tensor(class_ids).long()\n",
    "        return image, target, filename\n",
    "\n",
    "    def get_image(self, index):\n",
    "        filename = self.image_files[index]\n",
    "        image_path = os.path.join(self.data_dir, self.phase, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        return filename, image\n",
    "\n",
    "    def get_label(self, filename):\n",
    "        image_id = filename.split('.')[0]\n",
    "        meta_data = data_df[data_df['ImageID'] == image_id]\n",
    "        cate_names = meta_data['LabelName'].values\n",
    "        class_ids = [CLASS_NAME_TO_ID[cate_name] for cate_name in cate_names]\n",
    "        bboxes = meta_data[['XMin', 'XMax', 'YMin', 'YMax']].values\n",
    "        bboxes[:, [1, 2]] = bboxes[:, [2, 1]]\n",
    "        return bboxes, class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25df2271-97ef-4269-bd27-39839415426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Detection_dataset(data_dir=data_dir, phase='train', transformer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae87eca1-0002-4bfa-8c79-4485207f4917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    image_list = []\n",
    "    target_list = []\n",
    "    filename_list = []\n",
    "\n",
    "    for img, target, filename in batch:\n",
    "        image_list.append(img)\n",
    "        target_list.append(target)\n",
    "        filename_list.append(filename)\n",
    "    \n",
    "    return image_list, target_list, filename_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48428646-1631-49f4-9518-12e1eb0abdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_dataloader(data_dir, batch_size=4, image_size=448):\n",
    "#     transformer = transforms.Compose([\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Resize(size=(image_size, image_size)),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ])\n",
    "#     dataloaders = {}\n",
    "#     train_dataset = Detection_dataset(data_dir=data_dir, phase='train', transformer=transformer)\n",
    "#     dataloaders['train'] = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "#     val_dataset = Detection_dataset(data_dir=data_dir, phase='val', transformer=transformer)\n",
    "#     dataloaders['val'] = DataLoader(train_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
    "#     return dataloaders\n",
    "def build_dataloader(data_dir, batch_size=4, image_size=448):\n",
    "    transformer = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize(size=(image_size, image_size)),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    dataloaders = {}\n",
    "    train_dataset = Detection_dataset(data_dir=data_dir, phase='train', transformer=transformer)\n",
    "    dataloaders['train'] = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    val_dataset = Detection_dataset(data_dir=data_dir, phase='val', transformer=transformer)\n",
    "    dataloaders['val'] = DataLoader(train_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53c6b7f6-5eb6-44e3-84c5-6fd8e8440ff8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m BATCH_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m----> 2\u001b[0m trainset \u001b[38;5;241m=\u001b[39m Detection_dataset(data_dir\u001b[38;5;241m=\u001b[39mdata_dir, phase\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, transformer\u001b[38;5;241m=\u001b[39m\u001b[43mtransformer\u001b[49m)\n\u001b[1;32m      3\u001b[0m tranloader \u001b[38;5;241m=\u001b[39m DataLoader(trainset, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39mcollate_fn)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transformer' is not defined"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 8\n",
    "trainset = Detection_dataset(data_dir=data_dir, phase='train', transformer=transformer)\n",
    "tranloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca010a67-13d5-4c66-93fd-b449c06c38ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_model(num_classes):\n",
    "#     model = models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "#     in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "#     model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "#     return model\n",
    "def build_model(num_classes):\n",
    "    model = models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15771f24-a8e9-4773-a73f-e34fc6f5de15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0-3): 4 x Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = 2\n",
    "model = build_model(num_classes=NUM_CLASSES)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "513f3c80-abc3-4ca6-8abe-de3a8fc21b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_one_epoch(dataloaders, model, optimizer, device):\n",
    "#     train_loss = defaultdict(float)\n",
    "#     val_loss = defaultdict(float)\n",
    "#     model.train()\n",
    "\n",
    "#     for phase in ['train', 'val']:\n",
    "#         for index, batch in enumerate(dataloaders[phase]):\n",
    "#             images = batch[0]\n",
    "#             targets = batch[1]\n",
    "#             filenames = batch[2]\n",
    "\n",
    "#             images = list(image for image in images)\n",
    "#             targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "\n",
    "#             with torch.set_grad_enabled(phase == 'train'):\n",
    "#                 loss = model(images, targets)\n",
    "\n",
    "#         total_loss = sum(each_loss for each_loss in loss.values())\n",
    "\n",
    "#         if phase == 'train':\n",
    "#             optimizer.zero_grad()\n",
    "#             total_loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             if(index > 0) and (index % VERBOSE_FREQ == 0):\n",
    "#                 text = f\"{index}/{len(dataloaders[phase])} - \"\n",
    "#                 for k, v in loss.item():\n",
    "#                     text += f\"{k}: {v.item():.4f} \"\n",
    "#                 print(text)\n",
    "\n",
    "#             for k, v, in loss.items():\n",
    "#                 train_loss[k] += v.item()\n",
    "#             train_loss['total_loss'] += total_loss.item()\n",
    "#         else:\n",
    "#             for k, v, in loss.items():\n",
    "#                 val_loss[k] += v.item()\n",
    "#             val_loss['total_loss'] += total_loss.item()\n",
    "        \n",
    "#     for k in train_loss.keys():\n",
    "#         train_loss[k] /= len(dataloaders['train'])\n",
    "#         val_loss[k] /= len(dataloaders['val'])\n",
    "#     return train_loss, val_loss\n",
    "def train_one_epoch(dataloaders, model, optimizer, device):\n",
    "    train_loss = defaultdict(float)\n",
    "    val_loss = defaultdict(float)\n",
    "    model.train()\n",
    "\n",
    "    for phase in ['train', 'val']:\n",
    "        for index, batch in enumerate(dataloaders[phase]):\n",
    "            images = batch[0]\n",
    "            targets = batch[1]\n",
    "            filenames = batch[2]\n",
    "\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                loss_dict = model(images, targets)\n",
    "                loss = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "            if phase == 'train':\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if(index > 0) and (index % VERBOSE_FREQ == 0):\n",
    "                    text = f\"{index}/{len(dataloaders[phase])} - \"\n",
    "                    for k, v in loss_dict.items():\n",
    "                        text += f\"{k}: {v.item():.4f} \"\n",
    "                    print(text)\n",
    "\n",
    "            for k, v in loss_dict.items():\n",
    "                if phase == 'train':\n",
    "                    train_loss[k] += v.item()\n",
    "                else:\n",
    "                    val_loss[k] += v.item()\n",
    "            \n",
    "            if phase == 'train':\n",
    "                train_loss['total_loss'] += loss.item()\n",
    "            else:\n",
    "                val_loss['total_loss'] += loss.item()\n",
    "        \n",
    "    for k in train_loss.keys():\n",
    "        train_loss[k] /= len(dataloaders['train'])\n",
    "        val_loss[k] /= len(dataloaders['val'])\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18c79a58-acb5-436a-be3c-2b4e4d0cc241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_cuda = False\n",
    "\n",
    "# NUM_CLASSES = 2\n",
    "# IMAGE_SIZE = 448\n",
    "# BATCH_SIZE = 8\n",
    "# VERBOSE_FREQ = 100\n",
    "# DEVICE = torch.device('cuda' if torch.cuda.is_available and is_cuda else 'cpu')\n",
    "\n",
    "# dataloaders = build_dataloader(data_dir=data_dir, batch_size=BATCH_SIZE, image_size=IMAGE_SIZE)\n",
    "# model = build_model(num_classes=NUM_CLASSES)\n",
    "# model = model.to(DEVICE)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "is_cuda = True  # CUDA 사용 설정\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "IMAGE_SIZE = 448\n",
    "BATCH_SIZE = 8\n",
    "VERBOSE_FREQ = 100\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() and is_cuda else 'cpu')\n",
    "\n",
    "dataloaders = build_dataloader(data_dir=data_dir, batch_size=BATCH_SIZE, image_size=IMAGE_SIZE)\n",
    "model = build_model(num_classes=NUM_CLASSES)\n",
    "model = model.to(DEVICE)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5262d0d3-8038-4d5e-adf9-3cf23690ed42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2024, 7, 28, 12, 20, 23, 511292)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a1f23e-5d29-4e6e-9940-2b4e75b66869",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/1713 - loss_classifier: 0.1031 loss_box_reg: 0.1061 loss_objectness: 0.0639 loss_rpn_box_reg: 0.0308 \n",
      "200/1713 - loss_classifier: 0.0718 loss_box_reg: 0.0996 loss_objectness: 0.0080 loss_rpn_box_reg: 0.0041 \n",
      "300/1713 - loss_classifier: 0.0548 loss_box_reg: 0.0559 loss_objectness: 0.0144 loss_rpn_box_reg: 0.0050 \n",
      "400/1713 - loss_classifier: 0.0333 loss_box_reg: 0.0314 loss_objectness: 0.0066 loss_rpn_box_reg: 0.0061 \n",
      "500/1713 - loss_classifier: 0.0620 loss_box_reg: 0.0666 loss_objectness: 0.0117 loss_rpn_box_reg: 0.0052 \n",
      "600/1713 - loss_classifier: 0.0395 loss_box_reg: 0.0531 loss_objectness: 0.0860 loss_rpn_box_reg: 0.0216 \n",
      "700/1713 - loss_classifier: 0.0396 loss_box_reg: 0.0165 loss_objectness: 0.0056 loss_rpn_box_reg: 0.0033 \n",
      "800/1713 - loss_classifier: 0.0858 loss_box_reg: 0.0665 loss_objectness: 0.0606 loss_rpn_box_reg: 0.0123 \n",
      "900/1713 - loss_classifier: 0.0359 loss_box_reg: 0.0236 loss_objectness: 0.0103 loss_rpn_box_reg: 0.0029 \n",
      "1000/1713 - loss_classifier: 0.0345 loss_box_reg: 0.0537 loss_objectness: 0.0076 loss_rpn_box_reg: 0.0040 \n",
      "1100/1713 - loss_classifier: 0.0252 loss_box_reg: 0.0448 loss_objectness: 0.0062 loss_rpn_box_reg: 0.0035 \n",
      "1200/1713 - loss_classifier: 0.0432 loss_box_reg: 0.0612 loss_objectness: 0.0416 loss_rpn_box_reg: 0.0217 \n",
      "1300/1713 - loss_classifier: 0.0380 loss_box_reg: 0.0614 loss_objectness: 0.0083 loss_rpn_box_reg: 0.0063 \n",
      "1400/1713 - loss_classifier: 0.0464 loss_box_reg: 0.0515 loss_objectness: 0.0423 loss_rpn_box_reg: 0.0050 \n",
      "1500/1713 - loss_classifier: 0.0334 loss_box_reg: 0.0352 loss_objectness: 0.0045 loss_rpn_box_reg: 0.0089 \n",
      "1600/1713 - loss_classifier: 0.0288 loss_box_reg: 0.0415 loss_objectness: 0.0067 loss_rpn_box_reg: 0.0031 \n",
      "1700/1713 - loss_classifier: 0.0258 loss_box_reg: 0.0365 loss_objectness: 0.0064 loss_rpn_box_reg: 0.0023 \n",
      "epoch:1/50 - Train Loss:0.1279, Val Loss:0.1007\n",
      "========== 853.8566465377808 ==========\n",
      "100/1713 - loss_classifier: 0.1172 loss_box_reg: 0.1537 loss_objectness: 0.0302 loss_rpn_box_reg: 0.0075 \n",
      "200/1713 - loss_classifier: 0.0306 loss_box_reg: 0.0261 loss_objectness: 0.0032 loss_rpn_box_reg: 0.0049 \n",
      "300/1713 - loss_classifier: 0.0141 loss_box_reg: 0.0181 loss_objectness: 0.0023 loss_rpn_box_reg: 0.0012 \n",
      "400/1713 - loss_classifier: 0.0184 loss_box_reg: 0.0290 loss_objectness: 0.0175 loss_rpn_box_reg: 0.0067 \n",
      "500/1713 - loss_classifier: 0.0492 loss_box_reg: 0.0720 loss_objectness: 0.0077 loss_rpn_box_reg: 0.0073 \n",
      "600/1713 - loss_classifier: 0.0144 loss_box_reg: 0.0228 loss_objectness: 0.0091 loss_rpn_box_reg: 0.0037 \n",
      "700/1713 - loss_classifier: 0.0497 loss_box_reg: 0.0732 loss_objectness: 0.0191 loss_rpn_box_reg: 0.0189 \n",
      "800/1713 - loss_classifier: 0.0420 loss_box_reg: 0.0422 loss_objectness: 0.0211 loss_rpn_box_reg: 0.0151 \n",
      "900/1713 - loss_classifier: 0.0352 loss_box_reg: 0.0242 loss_objectness: 0.0024 loss_rpn_box_reg: 0.0062 \n",
      "1000/1713 - loss_classifier: 0.0385 loss_box_reg: 0.0326 loss_objectness: 0.0131 loss_rpn_box_reg: 0.0103 \n",
      "1100/1713 - loss_classifier: 0.0652 loss_box_reg: 0.0998 loss_objectness: 0.0095 loss_rpn_box_reg: 0.0103 \n",
      "1200/1713 - loss_classifier: 0.0601 loss_box_reg: 0.0433 loss_objectness: 0.0188 loss_rpn_box_reg: 0.0083 \n",
      "1300/1713 - loss_classifier: 0.0253 loss_box_reg: 0.0253 loss_objectness: 0.0243 loss_rpn_box_reg: 0.0047 \n",
      "1400/1713 - loss_classifier: 0.0213 loss_box_reg: 0.0245 loss_objectness: 0.0065 loss_rpn_box_reg: 0.0057 \n",
      "1500/1713 - loss_classifier: 0.0074 loss_box_reg: 0.0090 loss_objectness: 0.0037 loss_rpn_box_reg: 0.0022 \n",
      "1600/1713 - loss_classifier: 0.0304 loss_box_reg: 0.0255 loss_objectness: 0.0132 loss_rpn_box_reg: 0.0049 \n",
      "1700/1713 - loss_classifier: 0.0278 loss_box_reg: 0.0406 loss_objectness: 0.0083 loss_rpn_box_reg: 0.0023 \n",
      "epoch:2/50 - Train Loss:0.0994, Val Loss:0.0918\n",
      "========== 836.4939923286438 ==========\n",
      "100/1713 - loss_classifier: 0.0267 loss_box_reg: 0.0285 loss_objectness: 0.0281 loss_rpn_box_reg: 0.0318 \n",
      "200/1713 - loss_classifier: 0.0710 loss_box_reg: 0.0459 loss_objectness: 0.0202 loss_rpn_box_reg: 0.0086 \n",
      "300/1713 - loss_classifier: 0.0274 loss_box_reg: 0.0338 loss_objectness: 0.0077 loss_rpn_box_reg: 0.0041 \n",
      "400/1713 - loss_classifier: 0.0625 loss_box_reg: 0.0689 loss_objectness: 0.0102 loss_rpn_box_reg: 0.0063 \n",
      "500/1713 - loss_classifier: 0.0382 loss_box_reg: 0.0366 loss_objectness: 0.0143 loss_rpn_box_reg: 0.0062 \n",
      "600/1713 - loss_classifier: 0.0363 loss_box_reg: 0.0403 loss_objectness: 0.0059 loss_rpn_box_reg: 0.0043 \n",
      "700/1713 - loss_classifier: 0.0239 loss_box_reg: 0.0404 loss_objectness: 0.0122 loss_rpn_box_reg: 0.0047 \n",
      "800/1713 - loss_classifier: 0.0576 loss_box_reg: 0.0945 loss_objectness: 0.0068 loss_rpn_box_reg: 0.0051 \n",
      "900/1713 - loss_classifier: 0.0582 loss_box_reg: 0.0834 loss_objectness: 0.0082 loss_rpn_box_reg: 0.0061 \n",
      "1000/1713 - loss_classifier: 0.0169 loss_box_reg: 0.0155 loss_objectness: 0.0060 loss_rpn_box_reg: 0.0054 \n",
      "1100/1713 - loss_classifier: 0.0417 loss_box_reg: 0.0625 loss_objectness: 0.0021 loss_rpn_box_reg: 0.0033 \n",
      "1200/1713 - loss_classifier: 0.0490 loss_box_reg: 0.0584 loss_objectness: 0.0174 loss_rpn_box_reg: 0.0068 \n",
      "1300/1713 - loss_classifier: 0.0408 loss_box_reg: 0.0657 loss_objectness: 0.0029 loss_rpn_box_reg: 0.0049 \n",
      "1400/1713 - loss_classifier: 0.0288 loss_box_reg: 0.0228 loss_objectness: 0.0072 loss_rpn_box_reg: 0.0028 \n",
      "1500/1713 - loss_classifier: 0.0177 loss_box_reg: 0.0165 loss_objectness: 0.0063 loss_rpn_box_reg: 0.0039 \n",
      "1600/1713 - loss_classifier: 0.0308 loss_box_reg: 0.0560 loss_objectness: 0.0049 loss_rpn_box_reg: 0.0127 \n",
      "1700/1713 - loss_classifier: 0.0448 loss_box_reg: 0.0822 loss_objectness: 0.0283 loss_rpn_box_reg: 0.0104 \n",
      "epoch:3/50 - Train Loss:0.0913, Val Loss:0.0836\n",
      "========== 834.7189464569092 ==========\n",
      "100/1713 - loss_classifier: 0.0282 loss_box_reg: 0.0420 loss_objectness: 0.0038 loss_rpn_box_reg: 0.0019 \n",
      "200/1713 - loss_classifier: 0.0632 loss_box_reg: 0.0646 loss_objectness: 0.0170 loss_rpn_box_reg: 0.0127 \n",
      "300/1713 - loss_classifier: 0.0379 loss_box_reg: 0.0613 loss_objectness: 0.0064 loss_rpn_box_reg: 0.0041 \n",
      "400/1713 - loss_classifier: 0.0240 loss_box_reg: 0.0322 loss_objectness: 0.0045 loss_rpn_box_reg: 0.0098 \n",
      "500/1713 - loss_classifier: 0.0443 loss_box_reg: 0.0512 loss_objectness: 0.0041 loss_rpn_box_reg: 0.0014 \n",
      "600/1713 - loss_classifier: 0.0297 loss_box_reg: 0.0315 loss_objectness: 0.0157 loss_rpn_box_reg: 0.0056 \n",
      "700/1713 - loss_classifier: 0.0161 loss_box_reg: 0.0026 loss_objectness: 0.0087 loss_rpn_box_reg: 0.0046 \n",
      "800/1713 - loss_classifier: 0.0409 loss_box_reg: 0.0421 loss_objectness: 0.0120 loss_rpn_box_reg: 0.0040 \n",
      "900/1713 - loss_classifier: 0.0172 loss_box_reg: 0.0279 loss_objectness: 0.0021 loss_rpn_box_reg: 0.0032 \n",
      "1000/1713 - loss_classifier: 0.0646 loss_box_reg: 0.0692 loss_objectness: 0.0049 loss_rpn_box_reg: 0.0047 \n",
      "1100/1713 - loss_classifier: 0.0119 loss_box_reg: 0.0113 loss_objectness: 0.0041 loss_rpn_box_reg: 0.0039 \n",
      "1200/1713 - loss_classifier: 0.0463 loss_box_reg: 0.0581 loss_objectness: 0.0056 loss_rpn_box_reg: 0.0039 \n",
      "1300/1713 - loss_classifier: 0.0279 loss_box_reg: 0.0370 loss_objectness: 0.0051 loss_rpn_box_reg: 0.0045 \n",
      "1400/1713 - loss_classifier: 0.0251 loss_box_reg: 0.0185 loss_objectness: 0.0058 loss_rpn_box_reg: 0.0050 \n",
      "1500/1713 - loss_classifier: 0.0727 loss_box_reg: 0.0727 loss_objectness: 0.0033 loss_rpn_box_reg: 0.0033 \n",
      "1600/1713 - loss_classifier: 0.0235 loss_box_reg: 0.0261 loss_objectness: 0.0025 loss_rpn_box_reg: 0.0024 \n",
      "1700/1713 - loss_classifier: 0.0202 loss_box_reg: 0.0254 loss_objectness: 0.0205 loss_rpn_box_reg: 0.0287 \n",
      "epoch:4/50 - Train Loss:0.0846, Val Loss:0.0792\n",
      "========== 834.4897394180298 ==========\n",
      "100/1713 - loss_classifier: 0.0226 loss_box_reg: 0.0416 loss_objectness: 0.0051 loss_rpn_box_reg: 0.0037 \n",
      "200/1713 - loss_classifier: 0.0175 loss_box_reg: 0.0263 loss_objectness: 0.0006 loss_rpn_box_reg: 0.0015 \n",
      "300/1713 - loss_classifier: 0.0104 loss_box_reg: 0.0111 loss_objectness: 0.0011 loss_rpn_box_reg: 0.0028 \n",
      "400/1713 - loss_classifier: 0.0538 loss_box_reg: 0.1260 loss_objectness: 0.0073 loss_rpn_box_reg: 0.0129 \n",
      "500/1713 - loss_classifier: 0.0363 loss_box_reg: 0.0516 loss_objectness: 0.0011 loss_rpn_box_reg: 0.0014 \n",
      "600/1713 - loss_classifier: 0.0094 loss_box_reg: 0.0130 loss_objectness: 0.0037 loss_rpn_box_reg: 0.0116 \n",
      "700/1713 - loss_classifier: 0.0107 loss_box_reg: 0.0086 loss_objectness: 0.0059 loss_rpn_box_reg: 0.0039 \n",
      "800/1713 - loss_classifier: 0.0234 loss_box_reg: 0.0374 loss_objectness: 0.0071 loss_rpn_box_reg: 0.0074 \n",
      "900/1713 - loss_classifier: 0.0401 loss_box_reg: 0.0641 loss_objectness: 0.0106 loss_rpn_box_reg: 0.0050 \n",
      "1000/1713 - loss_classifier: 0.0571 loss_box_reg: 0.0534 loss_objectness: 0.0041 loss_rpn_box_reg: 0.0029 \n",
      "1100/1713 - loss_classifier: 0.0911 loss_box_reg: 0.0896 loss_objectness: 0.0091 loss_rpn_box_reg: 0.0061 \n",
      "1200/1713 - loss_classifier: 0.0053 loss_box_reg: 0.0055 loss_objectness: 0.0134 loss_rpn_box_reg: 0.0175 \n",
      "1300/1713 - loss_classifier: 0.0622 loss_box_reg: 0.0892 loss_objectness: 0.0121 loss_rpn_box_reg: 0.0119 \n",
      "1400/1713 - loss_classifier: 0.0117 loss_box_reg: 0.0198 loss_objectness: 0.0079 loss_rpn_box_reg: 0.0015 \n",
      "1500/1713 - loss_classifier: 0.0188 loss_box_reg: 0.0253 loss_objectness: 0.0029 loss_rpn_box_reg: 0.0022 \n",
      "1600/1713 - loss_classifier: 0.1717 loss_box_reg: 0.1935 loss_objectness: 0.0470 loss_rpn_box_reg: 0.0505 \n",
      "1700/1713 - loss_classifier: 0.0426 loss_box_reg: 0.0508 loss_objectness: 0.0113 loss_rpn_box_reg: 0.0121 \n",
      "epoch:5/50 - Train Loss:0.0795, Val Loss:0.0743\n",
      "========== 834.4527585506439 ==========\n",
      "100/1713 - loss_classifier: 0.0185 loss_box_reg: 0.0153 loss_objectness: 0.0514 loss_rpn_box_reg: 0.0138 \n",
      "200/1713 - loss_classifier: 0.0078 loss_box_reg: 0.0161 loss_objectness: 0.0019 loss_rpn_box_reg: 0.0044 \n",
      "300/1713 - loss_classifier: 0.0184 loss_box_reg: 0.0517 loss_objectness: 0.0031 loss_rpn_box_reg: 0.0049 \n",
      "400/1713 - loss_classifier: 0.0174 loss_box_reg: 0.0255 loss_objectness: 0.0022 loss_rpn_box_reg: 0.0059 \n",
      "500/1713 - loss_classifier: 0.0210 loss_box_reg: 0.0349 loss_objectness: 0.0045 loss_rpn_box_reg: 0.0024 \n",
      "600/1713 - loss_classifier: 0.0190 loss_box_reg: 0.0384 loss_objectness: 0.0047 loss_rpn_box_reg: 0.0064 \n",
      "700/1713 - loss_classifier: 0.0172 loss_box_reg: 0.0246 loss_objectness: 0.0040 loss_rpn_box_reg: 0.0039 \n",
      "800/1713 - loss_classifier: 0.0115 loss_box_reg: 0.0134 loss_objectness: 0.0028 loss_rpn_box_reg: 0.0025 \n",
      "900/1713 - loss_classifier: 0.0303 loss_box_reg: 0.0372 loss_objectness: 0.0031 loss_rpn_box_reg: 0.0031 \n",
      "1000/1713 - loss_classifier: 0.0172 loss_box_reg: 0.0239 loss_objectness: 0.0015 loss_rpn_box_reg: 0.0019 \n",
      "1100/1713 - loss_classifier: 0.0203 loss_box_reg: 0.0285 loss_objectness: 0.0029 loss_rpn_box_reg: 0.0042 \n",
      "1200/1713 - loss_classifier: 0.0237 loss_box_reg: 0.0173 loss_objectness: 0.0055 loss_rpn_box_reg: 0.0060 \n",
      "1300/1713 - loss_classifier: 0.0086 loss_box_reg: 0.0071 loss_objectness: 0.0058 loss_rpn_box_reg: 0.0023 \n",
      "1400/1713 - loss_classifier: 0.0411 loss_box_reg: 0.0342 loss_objectness: 0.0043 loss_rpn_box_reg: 0.0020 \n",
      "1500/1713 - loss_classifier: 0.0118 loss_box_reg: 0.0143 loss_objectness: 0.0033 loss_rpn_box_reg: 0.0067 \n",
      "1600/1713 - loss_classifier: 0.0228 loss_box_reg: 0.0335 loss_objectness: 0.0080 loss_rpn_box_reg: 0.0049 \n",
      "1700/1713 - loss_classifier: 0.0120 loss_box_reg: 0.0086 loss_objectness: 0.0189 loss_rpn_box_reg: 0.0053 \n",
      "epoch:6/50 - Train Loss:0.0745, Val Loss:0.0692\n",
      "========== 834.4336068630219 ==========\n",
      "100/1713 - loss_classifier: 0.0182 loss_box_reg: 0.0269 loss_objectness: 0.0031 loss_rpn_box_reg: 0.0034 \n",
      "200/1713 - loss_classifier: 0.0174 loss_box_reg: 0.0210 loss_objectness: 0.0094 loss_rpn_box_reg: 0.0637 \n",
      "300/1713 - loss_classifier: 0.0286 loss_box_reg: 0.0385 loss_objectness: 0.0073 loss_rpn_box_reg: 0.0069 \n",
      "400/1713 - loss_classifier: 0.0277 loss_box_reg: 0.0308 loss_objectness: 0.0076 loss_rpn_box_reg: 0.0140 \n",
      "500/1713 - loss_classifier: 0.0226 loss_box_reg: 0.0208 loss_objectness: 0.0040 loss_rpn_box_reg: 0.0042 \n",
      "600/1713 - loss_classifier: 0.0162 loss_box_reg: 0.0199 loss_objectness: 0.0031 loss_rpn_box_reg: 0.0061 \n",
      "700/1713 - loss_classifier: 0.0097 loss_box_reg: 0.0129 loss_objectness: 0.0091 loss_rpn_box_reg: 0.0021 \n",
      "800/1713 - loss_classifier: 0.0075 loss_box_reg: 0.0181 loss_objectness: 0.0006 loss_rpn_box_reg: 0.0028 \n",
      "900/1713 - loss_classifier: 0.0191 loss_box_reg: 0.0302 loss_objectness: 0.0033 loss_rpn_box_reg: 0.0034 \n",
      "1000/1713 - loss_classifier: 0.0097 loss_box_reg: 0.0158 loss_objectness: 0.0096 loss_rpn_box_reg: 0.0108 \n",
      "1100/1713 - loss_classifier: 0.0467 loss_box_reg: 0.0623 loss_objectness: 0.0093 loss_rpn_box_reg: 0.0070 \n",
      "1200/1713 - loss_classifier: 0.0079 loss_box_reg: 0.0165 loss_objectness: 0.0043 loss_rpn_box_reg: 0.0047 \n",
      "1300/1713 - loss_classifier: 0.0338 loss_box_reg: 0.0574 loss_objectness: 0.0046 loss_rpn_box_reg: 0.0029 \n",
      "1400/1713 - loss_classifier: 0.0398 loss_box_reg: 0.0379 loss_objectness: 0.0162 loss_rpn_box_reg: 0.0235 \n",
      "1500/1713 - loss_classifier: 0.0077 loss_box_reg: 0.0052 loss_objectness: 0.0034 loss_rpn_box_reg: 0.0066 \n",
      "1600/1713 - loss_classifier: 0.0304 loss_box_reg: 0.0241 loss_objectness: 0.0105 loss_rpn_box_reg: 0.0137 \n",
      "1700/1713 - loss_classifier: 0.0412 loss_box_reg: 0.0668 loss_objectness: 0.0026 loss_rpn_box_reg: 0.0035 \n",
      "epoch:7/50 - Train Loss:0.0697, Val Loss:0.0644\n",
      "========== 835.3123002052307 ==========\n",
      "100/1713 - loss_classifier: 0.0344 loss_box_reg: 0.0735 loss_objectness: 0.0076 loss_rpn_box_reg: 0.0050 \n",
      "200/1713 - loss_classifier: 0.0260 loss_box_reg: 0.0396 loss_objectness: 0.0014 loss_rpn_box_reg: 0.0085 \n",
      "300/1713 - loss_classifier: 0.0271 loss_box_reg: 0.0284 loss_objectness: 0.0020 loss_rpn_box_reg: 0.0028 \n",
      "400/1713 - loss_classifier: 0.0154 loss_box_reg: 0.0212 loss_objectness: 0.0024 loss_rpn_box_reg: 0.0019 \n",
      "500/1713 - loss_classifier: 0.0149 loss_box_reg: 0.0124 loss_objectness: 0.0079 loss_rpn_box_reg: 0.0039 \n",
      "600/1713 - loss_classifier: 0.0139 loss_box_reg: 0.0307 loss_objectness: 0.0100 loss_rpn_box_reg: 0.0074 \n",
      "700/1713 - loss_classifier: 0.0193 loss_box_reg: 0.0446 loss_objectness: 0.0032 loss_rpn_box_reg: 0.0037 \n",
      "800/1713 - loss_classifier: 0.0231 loss_box_reg: 0.0484 loss_objectness: 0.0024 loss_rpn_box_reg: 0.0046 \n",
      "900/1713 - loss_classifier: 0.0442 loss_box_reg: 0.0746 loss_objectness: 0.0151 loss_rpn_box_reg: 0.0208 \n",
      "1000/1713 - loss_classifier: 0.0199 loss_box_reg: 0.0225 loss_objectness: 0.0018 loss_rpn_box_reg: 0.0024 \n",
      "1100/1713 - loss_classifier: 0.0076 loss_box_reg: 0.0097 loss_objectness: 0.0026 loss_rpn_box_reg: 0.0036 \n",
      "1200/1713 - loss_classifier: 0.0111 loss_box_reg: 0.0115 loss_objectness: 0.0005 loss_rpn_box_reg: 0.0020 \n",
      "1300/1713 - loss_classifier: 0.0186 loss_box_reg: 0.0272 loss_objectness: 0.0033 loss_rpn_box_reg: 0.0081 \n",
      "1400/1713 - loss_classifier: 0.0110 loss_box_reg: 0.0165 loss_objectness: 0.0058 loss_rpn_box_reg: 0.0032 \n",
      "1500/1713 - loss_classifier: 0.0256 loss_box_reg: 0.0336 loss_objectness: 0.0101 loss_rpn_box_reg: 0.0057 \n",
      "1600/1713 - loss_classifier: 0.0336 loss_box_reg: 0.0568 loss_objectness: 0.0010 loss_rpn_box_reg: 0.0036 \n",
      "1700/1713 - loss_classifier: 0.0113 loss_box_reg: 0.0246 loss_objectness: 0.0034 loss_rpn_box_reg: 0.0027 \n",
      "epoch:8/50 - Train Loss:0.0648, Val Loss:0.0598\n",
      "========== 834.5519740581512 ==========\n",
      "100/1713 - loss_classifier: 0.0134 loss_box_reg: 0.0138 loss_objectness: 0.0013 loss_rpn_box_reg: 0.0044 \n",
      "200/1713 - loss_classifier: 0.0117 loss_box_reg: 0.0167 loss_objectness: 0.0013 loss_rpn_box_reg: 0.0024 \n",
      "300/1713 - loss_classifier: 0.0163 loss_box_reg: 0.0224 loss_objectness: 0.0096 loss_rpn_box_reg: 0.0204 \n",
      "400/1713 - loss_classifier: 0.0118 loss_box_reg: 0.0201 loss_objectness: 0.0049 loss_rpn_box_reg: 0.0027 \n",
      "500/1713 - loss_classifier: 0.0078 loss_box_reg: 0.0094 loss_objectness: 0.0052 loss_rpn_box_reg: 0.0047 \n",
      "600/1713 - loss_classifier: 0.0198 loss_box_reg: 0.0368 loss_objectness: 0.0022 loss_rpn_box_reg: 0.0040 \n",
      "700/1713 - loss_classifier: 0.0257 loss_box_reg: 0.0482 loss_objectness: 0.0017 loss_rpn_box_reg: 0.0030 \n",
      "800/1713 - loss_classifier: 0.0207 loss_box_reg: 0.0284 loss_objectness: 0.0081 loss_rpn_box_reg: 0.0122 \n",
      "900/1713 - loss_classifier: 0.0199 loss_box_reg: 0.0445 loss_objectness: 0.0078 loss_rpn_box_reg: 0.0097 \n",
      "1000/1713 - loss_classifier: 0.0155 loss_box_reg: 0.0173 loss_objectness: 0.0044 loss_rpn_box_reg: 0.0024 \n",
      "1100/1713 - loss_classifier: 0.0232 loss_box_reg: 0.0286 loss_objectness: 0.0064 loss_rpn_box_reg: 0.0060 \n",
      "1200/1713 - loss_classifier: 0.0104 loss_box_reg: 0.0124 loss_objectness: 0.0064 loss_rpn_box_reg: 0.0055 \n",
      "1300/1713 - loss_classifier: 0.0516 loss_box_reg: 0.0959 loss_objectness: 0.0035 loss_rpn_box_reg: 0.0064 \n",
      "1400/1713 - loss_classifier: 0.0264 loss_box_reg: 0.0467 loss_objectness: 0.0019 loss_rpn_box_reg: 0.0032 \n",
      "1500/1713 - loss_classifier: 0.0149 loss_box_reg: 0.0229 loss_objectness: 0.0078 loss_rpn_box_reg: 0.0069 \n",
      "1600/1713 - loss_classifier: 0.0057 loss_box_reg: 0.0075 loss_objectness: 0.0009 loss_rpn_box_reg: 0.0019 \n",
      "1700/1713 - loss_classifier: 0.0184 loss_box_reg: 0.0207 loss_objectness: 0.0081 loss_rpn_box_reg: 0.0060 \n",
      "epoch:9/50 - Train Loss:0.0605, Val Loss:0.0563\n",
      "========== 834.8311231136322 ==========\n",
      "100/1713 - loss_classifier: 0.0070 loss_box_reg: 0.0067 loss_objectness: 0.0057 loss_rpn_box_reg: 0.0032 \n",
      "200/1713 - loss_classifier: 0.0291 loss_box_reg: 0.0351 loss_objectness: 0.0005 loss_rpn_box_reg: 0.0017 \n",
      "300/1713 - loss_classifier: 0.0384 loss_box_reg: 0.0603 loss_objectness: 0.0036 loss_rpn_box_reg: 0.0063 \n",
      "400/1713 - loss_classifier: 0.0343 loss_box_reg: 0.0534 loss_objectness: 0.0109 loss_rpn_box_reg: 0.0110 \n",
      "500/1713 - loss_classifier: 0.0291 loss_box_reg: 0.0490 loss_objectness: 0.0031 loss_rpn_box_reg: 0.0049 \n",
      "600/1713 - loss_classifier: 0.0178 loss_box_reg: 0.0328 loss_objectness: 0.0016 loss_rpn_box_reg: 0.0050 \n",
      "700/1713 - loss_classifier: 0.0130 loss_box_reg: 0.0165 loss_objectness: 0.0075 loss_rpn_box_reg: 0.0085 \n",
      "800/1713 - loss_classifier: 0.0306 loss_box_reg: 0.0459 loss_objectness: 0.0073 loss_rpn_box_reg: 0.0039 \n",
      "900/1713 - loss_classifier: 0.0245 loss_box_reg: 0.0403 loss_objectness: 0.0043 loss_rpn_box_reg: 0.0035 \n",
      "1000/1713 - loss_classifier: 0.0456 loss_box_reg: 0.0595 loss_objectness: 0.0079 loss_rpn_box_reg: 0.0064 \n",
      "1100/1713 - loss_classifier: 0.0192 loss_box_reg: 0.0383 loss_objectness: 0.0005 loss_rpn_box_reg: 0.0069 \n",
      "1200/1713 - loss_classifier: 0.0138 loss_box_reg: 0.0188 loss_objectness: 0.0056 loss_rpn_box_reg: 0.0028 \n",
      "1300/1713 - loss_classifier: 0.0180 loss_box_reg: 0.0306 loss_objectness: 0.0051 loss_rpn_box_reg: 0.0045 \n",
      "1400/1713 - loss_classifier: 0.0128 loss_box_reg: 0.0212 loss_objectness: 0.0021 loss_rpn_box_reg: 0.0041 \n",
      "1500/1713 - loss_classifier: 0.0180 loss_box_reg: 0.0295 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0015 \n",
      "1600/1713 - loss_classifier: 0.0245 loss_box_reg: 0.0261 loss_objectness: 0.0098 loss_rpn_box_reg: 0.0141 \n",
      "1700/1713 - loss_classifier: 0.0253 loss_box_reg: 0.0522 loss_objectness: 0.0029 loss_rpn_box_reg: 0.0037 \n",
      "epoch:10/50 - Train Loss:0.0565, Val Loss:0.0523\n",
      "========== 835.2176587581635 ==========\n",
      "========== 8368.359560966492 ==========\n",
      "100/1713 - loss_classifier: 0.0146 loss_box_reg: 0.0267 loss_objectness: 0.0006 loss_rpn_box_reg: 0.0020 \n",
      "200/1713 - loss_classifier: 0.0488 loss_box_reg: 0.0852 loss_objectness: 0.0028 loss_rpn_box_reg: 0.0073 \n",
      "300/1713 - loss_classifier: 0.0112 loss_box_reg: 0.0165 loss_objectness: 0.0004 loss_rpn_box_reg: 0.0018 \n",
      "400/1713 - loss_classifier: 0.0184 loss_box_reg: 0.0370 loss_objectness: 0.0013 loss_rpn_box_reg: 0.0031 \n",
      "500/1713 - loss_classifier: 0.0057 loss_box_reg: 0.0101 loss_objectness: 0.0009 loss_rpn_box_reg: 0.0021 \n",
      "600/1713 - loss_classifier: 0.0082 loss_box_reg: 0.0033 loss_objectness: 0.0028 loss_rpn_box_reg: 0.0069 \n",
      "700/1713 - loss_classifier: 0.0175 loss_box_reg: 0.0295 loss_objectness: 0.0028 loss_rpn_box_reg: 0.0055 \n",
      "800/1713 - loss_classifier: 0.0204 loss_box_reg: 0.0427 loss_objectness: 0.0046 loss_rpn_box_reg: 0.0067 \n",
      "900/1713 - loss_classifier: 0.0150 loss_box_reg: 0.0193 loss_objectness: 0.0048 loss_rpn_box_reg: 0.0033 \n",
      "1000/1713 - loss_classifier: 0.0093 loss_box_reg: 0.0171 loss_objectness: 0.0010 loss_rpn_box_reg: 0.0041 \n",
      "1100/1713 - loss_classifier: 0.0234 loss_box_reg: 0.0372 loss_objectness: 0.0017 loss_rpn_box_reg: 0.0040 \n",
      "1200/1713 - loss_classifier: 0.0200 loss_box_reg: 0.0351 loss_objectness: 0.0009 loss_rpn_box_reg: 0.0015 \n",
      "1300/1713 - loss_classifier: 0.0072 loss_box_reg: 0.0125 loss_objectness: 0.0056 loss_rpn_box_reg: 0.0021 \n",
      "1400/1713 - loss_classifier: 0.0200 loss_box_reg: 0.0383 loss_objectness: 0.0012 loss_rpn_box_reg: 0.0037 \n",
      "1500/1713 - loss_classifier: 0.0181 loss_box_reg: 0.0181 loss_objectness: 0.0021 loss_rpn_box_reg: 0.0055 \n",
      "1600/1713 - loss_classifier: 0.0227 loss_box_reg: 0.0383 loss_objectness: 0.0010 loss_rpn_box_reg: 0.0036 \n",
      "1700/1713 - loss_classifier: 0.0141 loss_box_reg: 0.0165 loss_objectness: 0.0016 loss_rpn_box_reg: 0.0025 \n",
      "epoch:11/50 - Train Loss:0.0536, Val Loss:0.0506\n",
      "========== 834.6972477436066 ==========\n",
      "100/1713 - loss_classifier: 0.0057 loss_box_reg: 0.0159 loss_objectness: 0.0049 loss_rpn_box_reg: 0.0045 \n",
      "200/1713 - loss_classifier: 0.0119 loss_box_reg: 0.0221 loss_objectness: 0.0017 loss_rpn_box_reg: 0.0040 \n",
      "300/1713 - loss_classifier: 0.0191 loss_box_reg: 0.0336 loss_objectness: 0.0007 loss_rpn_box_reg: 0.0013 \n",
      "400/1713 - loss_classifier: 0.0180 loss_box_reg: 0.0214 loss_objectness: 0.0018 loss_rpn_box_reg: 0.0038 \n",
      "500/1713 - loss_classifier: 0.0106 loss_box_reg: 0.0196 loss_objectness: 0.0013 loss_rpn_box_reg: 0.0071 \n",
      "600/1713 - loss_classifier: 0.0133 loss_box_reg: 0.0269 loss_objectness: 0.0024 loss_rpn_box_reg: 0.0190 \n",
      "700/1713 - loss_classifier: 0.0298 loss_box_reg: 0.0369 loss_objectness: 0.0012 loss_rpn_box_reg: 0.0036 \n",
      "800/1713 - loss_classifier: 0.0104 loss_box_reg: 0.0184 loss_objectness: 0.0064 loss_rpn_box_reg: 0.0099 \n",
      "900/1713 - loss_classifier: 0.0198 loss_box_reg: 0.0418 loss_objectness: 0.0025 loss_rpn_box_reg: 0.0028 \n",
      "1000/1713 - loss_classifier: 0.0142 loss_box_reg: 0.0136 loss_objectness: 0.0023 loss_rpn_box_reg: 0.0044 \n",
      "1100/1713 - loss_classifier: 0.0133 loss_box_reg: 0.0185 loss_objectness: 0.0072 loss_rpn_box_reg: 0.0029 \n",
      "1200/1713 - loss_classifier: 0.0172 loss_box_reg: 0.0308 loss_objectness: 0.0033 loss_rpn_box_reg: 0.0022 \n",
      "1300/1713 - loss_classifier: 0.0214 loss_box_reg: 0.0452 loss_objectness: 0.0085 loss_rpn_box_reg: 0.0032 \n",
      "1400/1713 - loss_classifier: 0.0106 loss_box_reg: 0.0256 loss_objectness: 0.0045 loss_rpn_box_reg: 0.0019 \n",
      "1500/1713 - loss_classifier: 0.0074 loss_box_reg: 0.0128 loss_objectness: 0.0040 loss_rpn_box_reg: 0.0016 \n",
      "1600/1713 - loss_classifier: 0.0262 loss_box_reg: 0.0469 loss_objectness: 0.0030 loss_rpn_box_reg: 0.0033 \n",
      "1700/1713 - loss_classifier: 0.0081 loss_box_reg: 0.0124 loss_objectness: 0.0041 loss_rpn_box_reg: 0.0051 \n",
      "epoch:12/50 - Train Loss:0.0504, Val Loss:0.0468\n",
      "========== 837.4042313098907 ==========\n",
      "100/1713 - loss_classifier: 0.0101 loss_box_reg: 0.0221 loss_objectness: 0.0008 loss_rpn_box_reg: 0.0042 \n",
      "200/1713 - loss_classifier: 0.0166 loss_box_reg: 0.0374 loss_objectness: 0.0023 loss_rpn_box_reg: 0.0045 \n",
      "300/1713 - loss_classifier: 0.0130 loss_box_reg: 0.0271 loss_objectness: 0.0026 loss_rpn_box_reg: 0.0013 \n",
      "400/1713 - loss_classifier: 0.0139 loss_box_reg: 0.0314 loss_objectness: 0.0052 loss_rpn_box_reg: 0.0029 \n",
      "500/1713 - loss_classifier: 0.0169 loss_box_reg: 0.0268 loss_objectness: 0.0016 loss_rpn_box_reg: 0.0027 \n",
      "600/1713 - loss_classifier: 0.0091 loss_box_reg: 0.0085 loss_objectness: 0.0022 loss_rpn_box_reg: 0.0053 \n",
      "700/1713 - loss_classifier: 0.0260 loss_box_reg: 0.0366 loss_objectness: 0.0013 loss_rpn_box_reg: 0.0014 \n",
      "800/1713 - loss_classifier: 0.0079 loss_box_reg: 0.0184 loss_objectness: 0.0020 loss_rpn_box_reg: 0.0013 \n",
      "900/1713 - loss_classifier: 0.0167 loss_box_reg: 0.0465 loss_objectness: 0.0005 loss_rpn_box_reg: 0.0040 \n",
      "1000/1713 - loss_classifier: 0.0044 loss_box_reg: 0.0071 loss_objectness: 0.0025 loss_rpn_box_reg: 0.0039 \n",
      "1100/1713 - loss_classifier: 0.0023 loss_box_reg: 0.0045 loss_objectness: 0.0023 loss_rpn_box_reg: 0.0033 \n",
      "1200/1713 - loss_classifier: 0.0052 loss_box_reg: 0.0123 loss_objectness: 0.0051 loss_rpn_box_reg: 0.0049 \n",
      "1300/1713 - loss_classifier: 0.0097 loss_box_reg: 0.0111 loss_objectness: 0.0019 loss_rpn_box_reg: 0.0093 \n",
      "1400/1713 - loss_classifier: 0.0109 loss_box_reg: 0.0209 loss_objectness: 0.0045 loss_rpn_box_reg: 0.0058 \n",
      "1500/1713 - loss_classifier: 0.0315 loss_box_reg: 0.0610 loss_objectness: 0.0064 loss_rpn_box_reg: 0.0048 \n",
      "1600/1713 - loss_classifier: 0.0129 loss_box_reg: 0.0160 loss_objectness: 0.0006 loss_rpn_box_reg: 0.0016 \n",
      "1700/1713 - loss_classifier: 0.0085 loss_box_reg: 0.0118 loss_objectness: 0.0011 loss_rpn_box_reg: 0.0066 \n",
      "epoch:13/50 - Train Loss:0.0477, Val Loss:0.0447\n",
      "========== 836.3292803764343 ==========\n",
      "100/1713 - loss_classifier: 0.0216 loss_box_reg: 0.0188 loss_objectness: 0.0027 loss_rpn_box_reg: 0.0032 \n",
      "200/1713 - loss_classifier: 0.0167 loss_box_reg: 0.0204 loss_objectness: 0.0001 loss_rpn_box_reg: 0.0016 \n",
      "300/1713 - loss_classifier: 0.0110 loss_box_reg: 0.0174 loss_objectness: 0.0006 loss_rpn_box_reg: 0.0026 \n",
      "400/1713 - loss_classifier: 0.0200 loss_box_reg: 0.0287 loss_objectness: 0.0007 loss_rpn_box_reg: 0.0043 \n",
      "500/1713 - loss_classifier: 0.0132 loss_box_reg: 0.0172 loss_objectness: 0.0016 loss_rpn_box_reg: 0.0057 \n",
      "600/1713 - loss_classifier: 0.0093 loss_box_reg: 0.0104 loss_objectness: 0.0040 loss_rpn_box_reg: 0.0007 \n",
      "700/1713 - loss_classifier: 0.0115 loss_box_reg: 0.0138 loss_objectness: 0.0032 loss_rpn_box_reg: 0.0067 \n",
      "800/1713 - loss_classifier: 0.0252 loss_box_reg: 0.0501 loss_objectness: 0.0033 loss_rpn_box_reg: 0.0019 \n",
      "900/1713 - loss_classifier: 0.0080 loss_box_reg: 0.0107 loss_objectness: 0.0016 loss_rpn_box_reg: 0.0037 \n",
      "1000/1713 - loss_classifier: 0.0232 loss_box_reg: 0.0459 loss_objectness: 0.0035 loss_rpn_box_reg: 0.0075 \n",
      "1100/1713 - loss_classifier: 0.0097 loss_box_reg: 0.0130 loss_objectness: 0.0075 loss_rpn_box_reg: 0.0054 \n",
      "1200/1713 - loss_classifier: 0.0069 loss_box_reg: 0.0131 loss_objectness: 0.0029 loss_rpn_box_reg: 0.0022 \n",
      "1300/1713 - loss_classifier: 0.0323 loss_box_reg: 0.0702 loss_objectness: 0.0035 loss_rpn_box_reg: 0.0044 \n",
      "1400/1713 - loss_classifier: 0.0036 loss_box_reg: 0.0128 loss_objectness: 0.0015 loss_rpn_box_reg: 0.0017 \n",
      "1500/1713 - loss_classifier: 0.0149 loss_box_reg: 0.0244 loss_objectness: 0.0019 loss_rpn_box_reg: 0.0013 \n",
      "1600/1713 - loss_classifier: 0.0170 loss_box_reg: 0.0392 loss_objectness: 0.0007 loss_rpn_box_reg: 0.0041 \n",
      "1700/1713 - loss_classifier: 0.0176 loss_box_reg: 0.0214 loss_objectness: 0.0020 loss_rpn_box_reg: 0.0035 \n",
      "epoch:14/50 - Train Loss:0.0455, Val Loss:0.0436\n",
      "========== 834.8357090950012 ==========\n",
      "100/1713 - loss_classifier: 0.0231 loss_box_reg: 0.0442 loss_objectness: 0.0036 loss_rpn_box_reg: 0.0046 \n",
      "200/1713 - loss_classifier: 0.0140 loss_box_reg: 0.0161 loss_objectness: 0.0014 loss_rpn_box_reg: 0.0014 \n",
      "300/1713 - loss_classifier: 0.0219 loss_box_reg: 0.0373 loss_objectness: 0.0017 loss_rpn_box_reg: 0.0034 \n",
      "400/1713 - loss_classifier: 0.0169 loss_box_reg: 0.0274 loss_objectness: 0.0010 loss_rpn_box_reg: 0.0038 \n",
      "500/1713 - loss_classifier: 0.0036 loss_box_reg: 0.0071 loss_objectness: 0.0039 loss_rpn_box_reg: 0.0167 \n",
      "600/1713 - loss_classifier: 0.0129 loss_box_reg: 0.0221 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0053 \n",
      "700/1713 - loss_classifier: 0.0085 loss_box_reg: 0.0166 loss_objectness: 0.0012 loss_rpn_box_reg: 0.0011 \n",
      "800/1713 - loss_classifier: 0.0067 loss_box_reg: 0.0162 loss_objectness: 0.0040 loss_rpn_box_reg: 0.0024 \n",
      "900/1713 - loss_classifier: 0.0095 loss_box_reg: 0.0159 loss_objectness: 0.0038 loss_rpn_box_reg: 0.0088 \n",
      "1000/1713 - loss_classifier: 0.0054 loss_box_reg: 0.0089 loss_objectness: 0.0022 loss_rpn_box_reg: 0.0033 \n",
      "1100/1713 - loss_classifier: 0.0119 loss_box_reg: 0.0165 loss_objectness: 0.0021 loss_rpn_box_reg: 0.0030 \n",
      "1200/1713 - loss_classifier: 0.0069 loss_box_reg: 0.0185 loss_objectness: 0.0003 loss_rpn_box_reg: 0.0029 \n",
      "1300/1713 - loss_classifier: 0.0105 loss_box_reg: 0.0170 loss_objectness: 0.0023 loss_rpn_box_reg: 0.0025 \n",
      "1400/1713 - loss_classifier: 0.0159 loss_box_reg: 0.0321 loss_objectness: 0.0010 loss_rpn_box_reg: 0.0063 \n",
      "1500/1713 - loss_classifier: 0.0025 loss_box_reg: 0.0064 loss_objectness: 0.0048 loss_rpn_box_reg: 0.0045 \n",
      "1600/1713 - loss_classifier: 0.0110 loss_box_reg: 0.0182 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0016 \n",
      "1700/1713 - loss_classifier: 0.0174 loss_box_reg: 0.0282 loss_objectness: 0.0055 loss_rpn_box_reg: 0.0027 \n",
      "epoch:15/50 - Train Loss:0.0434, Val Loss:0.0404\n",
      "========== 835.2802197933197 ==========\n",
      "100/1713 - loss_classifier: 0.0063 loss_box_reg: 0.0074 loss_objectness: 0.0036 loss_rpn_box_reg: 0.0014 \n",
      "200/1713 - loss_classifier: 0.0158 loss_box_reg: 0.0233 loss_objectness: 0.0009 loss_rpn_box_reg: 0.0009 \n",
      "300/1713 - loss_classifier: 0.0116 loss_box_reg: 0.0235 loss_objectness: 0.0026 loss_rpn_box_reg: 0.0024 \n",
      "400/1713 - loss_classifier: 0.0082 loss_box_reg: 0.0134 loss_objectness: 0.0029 loss_rpn_box_reg: 0.0053 \n",
      "500/1713 - loss_classifier: 0.0059 loss_box_reg: 0.0062 loss_objectness: 0.0013 loss_rpn_box_reg: 0.0017 \n",
      "600/1713 - loss_classifier: 0.0345 loss_box_reg: 0.0751 loss_objectness: 0.0036 loss_rpn_box_reg: 0.0119 \n",
      "700/1713 - loss_classifier: 0.0065 loss_box_reg: 0.0097 loss_objectness: 0.0007 loss_rpn_box_reg: 0.0016 \n",
      "800/1713 - loss_classifier: 0.0036 loss_box_reg: 0.0056 loss_objectness: 0.0024 loss_rpn_box_reg: 0.0068 \n",
      "900/1713 - loss_classifier: 0.0298 loss_box_reg: 0.0467 loss_objectness: 0.0061 loss_rpn_box_reg: 0.0075 \n",
      "1000/1713 - loss_classifier: 0.0218 loss_box_reg: 0.0630 loss_objectness: 0.0033 loss_rpn_box_reg: 0.0100 \n",
      "1100/1713 - loss_classifier: 0.0051 loss_box_reg: 0.0099 loss_objectness: 0.0025 loss_rpn_box_reg: 0.0024 \n",
      "1200/1713 - loss_classifier: 0.0136 loss_box_reg: 0.0180 loss_objectness: 0.0006 loss_rpn_box_reg: 0.0042 \n",
      "1300/1713 - loss_classifier: 0.0114 loss_box_reg: 0.0202 loss_objectness: 0.0113 loss_rpn_box_reg: 0.0042 \n",
      "1400/1713 - loss_classifier: 0.0075 loss_box_reg: 0.0147 loss_objectness: 0.0005 loss_rpn_box_reg: 0.0023 \n",
      "1500/1713 - loss_classifier: 0.0151 loss_box_reg: 0.0191 loss_objectness: 0.0038 loss_rpn_box_reg: 0.0045 \n",
      "1600/1713 - loss_classifier: 0.0049 loss_box_reg: 0.0077 loss_objectness: 0.0009 loss_rpn_box_reg: 0.0035 \n",
      "1700/1713 - loss_classifier: 0.0114 loss_box_reg: 0.0155 loss_objectness: 0.0037 loss_rpn_box_reg: 0.0048 \n",
      "epoch:16/50 - Train Loss:0.0415, Val Loss:0.0389\n",
      "========== 836.5947153568268 ==========\n",
      "100/1713 - loss_classifier: 0.0133 loss_box_reg: 0.0260 loss_objectness: 0.0022 loss_rpn_box_reg: 0.0048 \n",
      "200/1713 - loss_classifier: 0.0194 loss_box_reg: 0.0263 loss_objectness: 0.0033 loss_rpn_box_reg: 0.0028 \n",
      "300/1713 - loss_classifier: 0.0128 loss_box_reg: 0.0195 loss_objectness: 0.0015 loss_rpn_box_reg: 0.0031 \n",
      "400/1713 - loss_classifier: 0.0137 loss_box_reg: 0.0079 loss_objectness: 0.0022 loss_rpn_box_reg: 0.0100 \n",
      "500/1713 - loss_classifier: 0.0185 loss_box_reg: 0.0314 loss_objectness: 0.0025 loss_rpn_box_reg: 0.0056 \n",
      "600/1713 - loss_classifier: 0.0095 loss_box_reg: 0.0225 loss_objectness: 0.0006 loss_rpn_box_reg: 0.0030 \n",
      "700/1713 - loss_classifier: 0.0068 loss_box_reg: 0.0127 loss_objectness: 0.0055 loss_rpn_box_reg: 0.0096 \n",
      "800/1713 - loss_classifier: 0.0029 loss_box_reg: 0.0056 loss_objectness: 0.0007 loss_rpn_box_reg: 0.0046 \n",
      "900/1713 - loss_classifier: 0.0191 loss_box_reg: 0.0268 loss_objectness: 0.0046 loss_rpn_box_reg: 0.0145 \n",
      "1000/1713 - loss_classifier: 0.0163 loss_box_reg: 0.0269 loss_objectness: 0.0004 loss_rpn_box_reg: 0.0015 \n",
      "1100/1713 - loss_classifier: 0.0160 loss_box_reg: 0.0221 loss_objectness: 0.0003 loss_rpn_box_reg: 0.0026 \n",
      "1200/1713 - loss_classifier: 0.0030 loss_box_reg: 0.0090 loss_objectness: 0.0024 loss_rpn_box_reg: 0.0024 \n",
      "1300/1713 - loss_classifier: 0.0181 loss_box_reg: 0.0212 loss_objectness: 0.0038 loss_rpn_box_reg: 0.0040 \n",
      "1400/1713 - loss_classifier: 0.0064 loss_box_reg: 0.0048 loss_objectness: 0.0030 loss_rpn_box_reg: 0.0037 \n",
      "1500/1713 - loss_classifier: 0.0112 loss_box_reg: 0.0212 loss_objectness: 0.0050 loss_rpn_box_reg: 0.0012 \n",
      "1600/1713 - loss_classifier: 0.0082 loss_box_reg: 0.0152 loss_objectness: 0.0017 loss_rpn_box_reg: 0.0029 \n",
      "1700/1713 - loss_classifier: 0.0105 loss_box_reg: 0.0206 loss_objectness: 0.0062 loss_rpn_box_reg: 0.0039 \n",
      "epoch:17/50 - Train Loss:0.0398, Val Loss:0.0377\n",
      "========== 839.2721540927887 ==========\n",
      "100/1713 - loss_classifier: 0.0182 loss_box_reg: 0.0196 loss_objectness: 0.0028 loss_rpn_box_reg: 0.0031 \n",
      "200/1713 - loss_classifier: 0.0042 loss_box_reg: 0.0079 loss_objectness: 0.0019 loss_rpn_box_reg: 0.0022 \n",
      "300/1713 - loss_classifier: 0.0070 loss_box_reg: 0.0158 loss_objectness: 0.0008 loss_rpn_box_reg: 0.0023 \n",
      "400/1713 - loss_classifier: 0.0008 loss_box_reg: 0.0023 loss_objectness: 0.0038 loss_rpn_box_reg: 0.0045 \n",
      "500/1713 - loss_classifier: 0.0104 loss_box_reg: 0.0137 loss_objectness: 0.0032 loss_rpn_box_reg: 0.0062 \n",
      "600/1713 - loss_classifier: 0.0042 loss_box_reg: 0.0104 loss_objectness: 0.0013 loss_rpn_box_reg: 0.0046 \n",
      "700/1713 - loss_classifier: 0.0081 loss_box_reg: 0.0185 loss_objectness: 0.0005 loss_rpn_box_reg: 0.0036 \n",
      "800/1713 - loss_classifier: 0.0095 loss_box_reg: 0.0218 loss_objectness: 0.0004 loss_rpn_box_reg: 0.0014 \n",
      "900/1713 - loss_classifier: 0.0043 loss_box_reg: 0.0049 loss_objectness: 0.0022 loss_rpn_box_reg: 0.0132 \n",
      "1000/1713 - loss_classifier: 0.0117 loss_box_reg: 0.0214 loss_objectness: 0.0009 loss_rpn_box_reg: 0.0031 \n",
      "1100/1713 - loss_classifier: 0.0080 loss_box_reg: 0.0145 loss_objectness: 0.0030 loss_rpn_box_reg: 0.0026 \n",
      "1200/1713 - loss_classifier: 0.0201 loss_box_reg: 0.0473 loss_objectness: 0.0023 loss_rpn_box_reg: 0.0030 \n",
      "1300/1713 - loss_classifier: 0.0077 loss_box_reg: 0.0141 loss_objectness: 0.0037 loss_rpn_box_reg: 0.0022 \n",
      "1400/1713 - loss_classifier: 0.0127 loss_box_reg: 0.0230 loss_objectness: 0.0033 loss_rpn_box_reg: 0.0020 \n",
      "1500/1713 - loss_classifier: 0.0149 loss_box_reg: 0.0344 loss_objectness: 0.0016 loss_rpn_box_reg: 0.0038 \n",
      "1600/1713 - loss_classifier: 0.0086 loss_box_reg: 0.0256 loss_objectness: 0.0025 loss_rpn_box_reg: 0.0079 \n",
      "1700/1713 - loss_classifier: 0.0173 loss_box_reg: 0.0301 loss_objectness: 0.0013 loss_rpn_box_reg: 0.0037 \n",
      "epoch:18/50 - Train Loss:0.0381, Val Loss:0.0361\n",
      "========== 838.2597060203552 ==========\n",
      "100/1713 - loss_classifier: 0.0046 loss_box_reg: 0.0130 loss_objectness: 0.0022 loss_rpn_box_reg: 0.0084 \n",
      "200/1713 - loss_classifier: 0.0042 loss_box_reg: 0.0080 loss_objectness: 0.0013 loss_rpn_box_reg: 0.0027 \n",
      "300/1713 - loss_classifier: 0.0118 loss_box_reg: 0.0144 loss_objectness: 0.0006 loss_rpn_box_reg: 0.0043 \n",
      "400/1713 - loss_classifier: 0.0170 loss_box_reg: 0.0410 loss_objectness: 0.0014 loss_rpn_box_reg: 0.0082 \n",
      "500/1713 - loss_classifier: 0.0052 loss_box_reg: 0.0057 loss_objectness: 0.0007 loss_rpn_box_reg: 0.0184 \n",
      "600/1713 - loss_classifier: 0.0054 loss_box_reg: 0.0093 loss_objectness: 0.0031 loss_rpn_box_reg: 0.0075 \n",
      "700/1713 - loss_classifier: 0.0014 loss_box_reg: 0.0022 loss_objectness: 0.0027 loss_rpn_box_reg: 0.0109 \n",
      "800/1713 - loss_classifier: 0.0197 loss_box_reg: 0.0256 loss_objectness: 0.0043 loss_rpn_box_reg: 0.0036 \n",
      "900/1713 - loss_classifier: 0.0064 loss_box_reg: 0.0168 loss_objectness: 0.0020 loss_rpn_box_reg: 0.0032 \n",
      "1000/1713 - loss_classifier: 0.0082 loss_box_reg: 0.0155 loss_objectness: 0.0063 loss_rpn_box_reg: 0.0060 \n",
      "1100/1713 - loss_classifier: 0.0097 loss_box_reg: 0.0169 loss_objectness: 0.0006 loss_rpn_box_reg: 0.0040 \n",
      "1200/1713 - loss_classifier: 0.0120 loss_box_reg: 0.0278 loss_objectness: 0.0003 loss_rpn_box_reg: 0.0031 \n",
      "1300/1713 - loss_classifier: 0.0297 loss_box_reg: 0.0722 loss_objectness: 0.0036 loss_rpn_box_reg: 0.0060 \n",
      "1400/1713 - loss_classifier: 0.0081 loss_box_reg: 0.0099 loss_objectness: 0.0011 loss_rpn_box_reg: 0.0018 \n",
      "1500/1713 - loss_classifier: 0.0102 loss_box_reg: 0.0218 loss_objectness: 0.0013 loss_rpn_box_reg: 0.0048 \n",
      "1600/1713 - loss_classifier: 0.0077 loss_box_reg: 0.0204 loss_objectness: 0.0030 loss_rpn_box_reg: 0.0028 \n",
      "1700/1713 - loss_classifier: 0.0072 loss_box_reg: 0.0071 loss_objectness: 0.0001 loss_rpn_box_reg: 0.0030 \n",
      "epoch:19/50 - Train Loss:0.0363, Val Loss:0.0349\n",
      "========== 841.0581901073456 ==========\n",
      "100/1713 - loss_classifier: 0.0088 loss_box_reg: 0.0166 loss_objectness: 0.0022 loss_rpn_box_reg: 0.0035 \n",
      "200/1713 - loss_classifier: 0.0185 loss_box_reg: 0.0219 loss_objectness: 0.0024 loss_rpn_box_reg: 0.0020 \n",
      "300/1713 - loss_classifier: 0.0035 loss_box_reg: 0.0054 loss_objectness: 0.0078 loss_rpn_box_reg: 0.0126 \n",
      "400/1713 - loss_classifier: 0.0078 loss_box_reg: 0.0135 loss_objectness: 0.0022 loss_rpn_box_reg: 0.0029 \n",
      "500/1713 - loss_classifier: 0.0144 loss_box_reg: 0.0327 loss_objectness: 0.0005 loss_rpn_box_reg: 0.0039 \n",
      "600/1713 - loss_classifier: 0.0138 loss_box_reg: 0.0202 loss_objectness: 0.0010 loss_rpn_box_reg: 0.0012 \n",
      "700/1713 - loss_classifier: 0.0098 loss_box_reg: 0.0178 loss_objectness: 0.0021 loss_rpn_box_reg: 0.0017 \n",
      "800/1713 - loss_classifier: 0.0083 loss_box_reg: 0.0101 loss_objectness: 0.0006 loss_rpn_box_reg: 0.0033 \n",
      "900/1713 - loss_classifier: 0.0022 loss_box_reg: 0.0015 loss_objectness: 0.0011 loss_rpn_box_reg: 0.0056 \n",
      "1000/1713 - loss_classifier: 0.0125 loss_box_reg: 0.0230 loss_objectness: 0.0005 loss_rpn_box_reg: 0.0011 \n",
      "1100/1713 - loss_classifier: 0.0057 loss_box_reg: 0.0055 loss_objectness: 0.0020 loss_rpn_box_reg: 0.0097 \n",
      "1200/1713 - loss_classifier: 0.0035 loss_box_reg: 0.0102 loss_objectness: 0.0027 loss_rpn_box_reg: 0.0018 \n",
      "1300/1713 - loss_classifier: 0.0062 loss_box_reg: 0.0123 loss_objectness: 0.0020 loss_rpn_box_reg: 0.0041 \n",
      "1400/1713 - loss_classifier: 0.0082 loss_box_reg: 0.0153 loss_objectness: 0.0005 loss_rpn_box_reg: 0.0024 \n",
      "1500/1713 - loss_classifier: 0.0089 loss_box_reg: 0.0105 loss_objectness: 0.0013 loss_rpn_box_reg: 0.0024 \n",
      "1600/1713 - loss_classifier: 0.0166 loss_box_reg: 0.0315 loss_objectness: 0.0014 loss_rpn_box_reg: 0.0255 \n",
      "1700/1713 - loss_classifier: 0.0080 loss_box_reg: 0.0096 loss_objectness: 0.0014 loss_rpn_box_reg: 0.0031 \n",
      "epoch:20/50 - Train Loss:0.0349, Val Loss:0.0340\n",
      "========== 834.9260110855103 ==========\n",
      "========== 16737.191692590714 ==========\n",
      "100/1713 - loss_classifier: 0.0076 loss_box_reg: 0.0225 loss_objectness: 0.0007 loss_rpn_box_reg: 0.0024 \n",
      "200/1713 - loss_classifier: 0.0070 loss_box_reg: 0.0097 loss_objectness: 0.0026 loss_rpn_box_reg: 0.0020 \n",
      "300/1713 - loss_classifier: 0.0125 loss_box_reg: 0.0185 loss_objectness: 0.0009 loss_rpn_box_reg: 0.0020 \n",
      "400/1713 - loss_classifier: 0.0163 loss_box_reg: 0.0337 loss_objectness: 0.0012 loss_rpn_box_reg: 0.0034 \n",
      "500/1713 - loss_classifier: 0.0065 loss_box_reg: 0.0131 loss_objectness: 0.0009 loss_rpn_box_reg: 0.0012 \n",
      "600/1713 - loss_classifier: 0.0044 loss_box_reg: 0.0087 loss_objectness: 0.0003 loss_rpn_box_reg: 0.0029 \n",
      "700/1713 - loss_classifier: 0.0061 loss_box_reg: 0.0155 loss_objectness: 0.0036 loss_rpn_box_reg: 0.0092 \n",
      "800/1713 - loss_classifier: 0.0109 loss_box_reg: 0.0186 loss_objectness: 0.0033 loss_rpn_box_reg: 0.0043 \n",
      "900/1713 - loss_classifier: 0.0053 loss_box_reg: 0.0092 loss_objectness: 0.0003 loss_rpn_box_reg: 0.0024 \n",
      "1000/1713 - loss_classifier: 0.0160 loss_box_reg: 0.0443 loss_objectness: 0.0040 loss_rpn_box_reg: 0.0045 \n",
      "1100/1713 - loss_classifier: 0.0064 loss_box_reg: 0.0119 loss_objectness: 0.0024 loss_rpn_box_reg: 0.0037 \n",
      "1200/1713 - loss_classifier: 0.0126 loss_box_reg: 0.0137 loss_objectness: 0.0024 loss_rpn_box_reg: 0.0023 \n",
      "1300/1713 - loss_classifier: 0.0015 loss_box_reg: 0.0038 loss_objectness: 0.0026 loss_rpn_box_reg: 0.0039 \n",
      "1400/1713 - loss_classifier: 0.0123 loss_box_reg: 0.0252 loss_objectness: 0.0058 loss_rpn_box_reg: 0.0051 \n",
      "1500/1713 - loss_classifier: 0.0092 loss_box_reg: 0.0118 loss_objectness: 0.0005 loss_rpn_box_reg: 0.0023 \n",
      "1600/1713 - loss_classifier: 0.0064 loss_box_reg: 0.0156 loss_objectness: 0.0008 loss_rpn_box_reg: 0.0054 \n",
      "1700/1713 - loss_classifier: 0.0084 loss_box_reg: 0.0216 loss_objectness: 0.0010 loss_rpn_box_reg: 0.0035 \n",
      "epoch:21/50 - Train Loss:0.0335, Val Loss:0.0320\n",
      "========== 837.932112455368 ==========\n",
      "100/1713 - loss_classifier: 0.0118 loss_box_reg: 0.0320 loss_objectness: 0.0004 loss_rpn_box_reg: 0.0032 \n",
      "200/1713 - loss_classifier: 0.0061 loss_box_reg: 0.0163 loss_objectness: 0.0007 loss_rpn_box_reg: 0.0012 \n",
      "300/1713 - loss_classifier: 0.0058 loss_box_reg: 0.0081 loss_objectness: 0.0004 loss_rpn_box_reg: 0.0028 \n",
      "400/1713 - loss_classifier: 0.0114 loss_box_reg: 0.0220 loss_objectness: 0.0001 loss_rpn_box_reg: 0.0014 \n",
      "500/1713 - loss_classifier: 0.0103 loss_box_reg: 0.0170 loss_objectness: 0.0004 loss_rpn_box_reg: 0.0030 \n",
      "600/1713 - loss_classifier: 0.0047 loss_box_reg: 0.0107 loss_objectness: 0.0056 loss_rpn_box_reg: 0.0078 \n",
      "700/1713 - loss_classifier: 0.0166 loss_box_reg: 0.0342 loss_objectness: 0.0012 loss_rpn_box_reg: 0.0021 \n",
      "800/1713 - loss_classifier: 0.0040 loss_box_reg: 0.0100 loss_objectness: 0.0001 loss_rpn_box_reg: 0.0011 \n",
      "900/1713 - loss_classifier: 0.0106 loss_box_reg: 0.0350 loss_objectness: 0.0020 loss_rpn_box_reg: 0.0049 \n",
      "1000/1713 - loss_classifier: 0.0074 loss_box_reg: 0.0133 loss_objectness: 0.0003 loss_rpn_box_reg: 0.0014 \n",
      "1100/1713 - loss_classifier: 0.0194 loss_box_reg: 0.0354 loss_objectness: 0.0047 loss_rpn_box_reg: 0.0033 \n",
      "1200/1713 - loss_classifier: 0.0095 loss_box_reg: 0.0230 loss_objectness: 0.0027 loss_rpn_box_reg: 0.0051 \n",
      "1300/1713 - loss_classifier: 0.0100 loss_box_reg: 0.0176 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0011 \n",
      "1400/1713 - loss_classifier: 0.0038 loss_box_reg: 0.0132 loss_objectness: 0.0009 loss_rpn_box_reg: 0.0057 \n",
      "1500/1713 - loss_classifier: 0.0078 loss_box_reg: 0.0176 loss_objectness: 0.0008 loss_rpn_box_reg: 0.0032 \n",
      "1600/1713 - loss_classifier: 0.0137 loss_box_reg: 0.0263 loss_objectness: 0.0015 loss_rpn_box_reg: 0.0068 \n",
      "1700/1713 - loss_classifier: 0.0107 loss_box_reg: 0.0258 loss_objectness: 0.0006 loss_rpn_box_reg: 0.0014 \n",
      "epoch:22/50 - Train Loss:0.0324, Val Loss:0.0307\n",
      "========== 839.6898145675659 ==========\n",
      "100/1713 - loss_classifier: 0.0114 loss_box_reg: 0.0326 loss_objectness: 0.0024 loss_rpn_box_reg: 0.0024 \n",
      "200/1713 - loss_classifier: 0.0112 loss_box_reg: 0.0232 loss_objectness: 0.0015 loss_rpn_box_reg: 0.0026 \n",
      "300/1713 - loss_classifier: 0.0054 loss_box_reg: 0.0119 loss_objectness: 0.0009 loss_rpn_box_reg: 0.0017 \n",
      "400/1713 - loss_classifier: 0.0136 loss_box_reg: 0.0222 loss_objectness: 0.0005 loss_rpn_box_reg: 0.0023 \n",
      "500/1713 - loss_classifier: 0.0085 loss_box_reg: 0.0135 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0032 \n",
      "600/1713 - loss_classifier: 0.0083 loss_box_reg: 0.0052 loss_objectness: 0.0055 loss_rpn_box_reg: 0.0044 \n",
      "700/1713 - loss_classifier: 0.0186 loss_box_reg: 0.0328 loss_objectness: 0.0005 loss_rpn_box_reg: 0.0029 \n",
      "800/1713 - loss_classifier: 0.0055 loss_box_reg: 0.0090 loss_objectness: 0.0007 loss_rpn_box_reg: 0.0034 \n",
      "900/1713 - loss_classifier: 0.0071 loss_box_reg: 0.0095 loss_objectness: 0.0026 loss_rpn_box_reg: 0.0025 \n",
      "1000/1713 - loss_classifier: 0.0100 loss_box_reg: 0.0174 loss_objectness: 0.0029 loss_rpn_box_reg: 0.0057 \n",
      "1100/1713 - loss_classifier: 0.0224 loss_box_reg: 0.0438 loss_objectness: 0.0034 loss_rpn_box_reg: 0.0105 \n",
      "1200/1713 - loss_classifier: 0.0162 loss_box_reg: 0.0274 loss_objectness: 0.0014 loss_rpn_box_reg: 0.0031 \n",
      "1300/1713 - loss_classifier: 0.0110 loss_box_reg: 0.0214 loss_objectness: 0.0031 loss_rpn_box_reg: 0.0042 \n",
      "1400/1713 - loss_classifier: 0.0053 loss_box_reg: 0.0075 loss_objectness: 0.0068 loss_rpn_box_reg: 0.0049 \n",
      "1500/1713 - loss_classifier: 0.0028 loss_box_reg: 0.0035 loss_objectness: 0.0013 loss_rpn_box_reg: 0.0051 \n",
      "1600/1713 - loss_classifier: 0.0069 loss_box_reg: 0.0108 loss_objectness: 0.0039 loss_rpn_box_reg: 0.0041 \n",
      "1700/1713 - loss_classifier: 0.0149 loss_box_reg: 0.0217 loss_objectness: 0.0023 loss_rpn_box_reg: 0.0007 \n",
      "epoch:23/50 - Train Loss:0.0312, Val Loss:0.0307\n",
      "========== 837.160386800766 ==========\n",
      "100/1713 - loss_classifier: 0.0104 loss_box_reg: 0.0254 loss_objectness: 0.0018 loss_rpn_box_reg: 0.0034 \n",
      "200/1713 - loss_classifier: 0.0059 loss_box_reg: 0.0053 loss_objectness: 0.0006 loss_rpn_box_reg: 0.0026 \n",
      "300/1713 - loss_classifier: 0.0062 loss_box_reg: 0.0102 loss_objectness: 0.0009 loss_rpn_box_reg: 0.0030 \n",
      "400/1713 - loss_classifier: 0.0024 loss_box_reg: 0.0039 loss_objectness: 0.0028 loss_rpn_box_reg: 0.0031 \n",
      "500/1713 - loss_classifier: 0.0144 loss_box_reg: 0.0325 loss_objectness: 0.0018 loss_rpn_box_reg: 0.0030 \n",
      "600/1713 - loss_classifier: 0.0039 loss_box_reg: 0.0055 loss_objectness: 0.0009 loss_rpn_box_reg: 0.0017 \n",
      "700/1713 - loss_classifier: 0.0069 loss_box_reg: 0.0100 loss_objectness: 0.0006 loss_rpn_box_reg: 0.0012 \n",
      "800/1713 - loss_classifier: 0.0132 loss_box_reg: 0.0227 loss_objectness: 0.0005 loss_rpn_box_reg: 0.0042 \n",
      "900/1713 - loss_classifier: 0.0215 loss_box_reg: 0.0452 loss_objectness: 0.0029 loss_rpn_box_reg: 0.0032 \n",
      "1000/1713 - loss_classifier: 0.0211 loss_box_reg: 0.0327 loss_objectness: 0.0005 loss_rpn_box_reg: 0.0042 \n",
      "1100/1713 - loss_classifier: 0.0106 loss_box_reg: 0.0165 loss_objectness: 0.0013 loss_rpn_box_reg: 0.0018 \n",
      "1200/1713 - loss_classifier: 0.0051 loss_box_reg: 0.0086 loss_objectness: 0.0003 loss_rpn_box_reg: 0.0023 \n",
      "1300/1713 - loss_classifier: 0.0044 loss_box_reg: 0.0112 loss_objectness: 0.0017 loss_rpn_box_reg: 0.0027 \n",
      "1400/1713 - loss_classifier: 0.0063 loss_box_reg: 0.0111 loss_objectness: 0.0007 loss_rpn_box_reg: 0.0031 \n",
      "1500/1713 - loss_classifier: 0.0082 loss_box_reg: 0.0183 loss_objectness: 0.0007 loss_rpn_box_reg: 0.0020 \n",
      "1600/1713 - loss_classifier: 0.0054 loss_box_reg: 0.0103 loss_objectness: 0.0004 loss_rpn_box_reg: 0.0014 \n",
      "1700/1713 - loss_classifier: 0.0046 loss_box_reg: 0.0082 loss_objectness: 0.0024 loss_rpn_box_reg: 0.0042 \n",
      "epoch:24/50 - Train Loss:0.0300, Val Loss:0.0293\n",
      "========== 842.7545022964478 ==========\n",
      "100/1713 - loss_classifier: 0.0058 loss_box_reg: 0.0116 loss_objectness: 0.0016 loss_rpn_box_reg: 0.0016 \n",
      "200/1713 - loss_classifier: 0.0090 loss_box_reg: 0.0167 loss_objectness: 0.0012 loss_rpn_box_reg: 0.0015 \n",
      "300/1713 - loss_classifier: 0.0049 loss_box_reg: 0.0122 loss_objectness: 0.0016 loss_rpn_box_reg: 0.0018 \n",
      "400/1713 - loss_classifier: 0.0088 loss_box_reg: 0.0199 loss_objectness: 0.0016 loss_rpn_box_reg: 0.0040 \n",
      "500/1713 - loss_classifier: 0.0299 loss_box_reg: 0.0612 loss_objectness: 0.0025 loss_rpn_box_reg: 0.0141 \n",
      "600/1713 - loss_classifier: 0.0105 loss_box_reg: 0.0216 loss_objectness: 0.0004 loss_rpn_box_reg: 0.0036 \n",
      "700/1713 - loss_classifier: 0.0039 loss_box_reg: 0.0068 loss_objectness: 0.0001 loss_rpn_box_reg: 0.0022 \n",
      "800/1713 - loss_classifier: 0.0069 loss_box_reg: 0.0091 loss_objectness: 0.0026 loss_rpn_box_reg: 0.0017 \n",
      "900/1713 - loss_classifier: 0.0026 loss_box_reg: 0.0021 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0017 \n",
      "1000/1713 - loss_classifier: 0.0078 loss_box_reg: 0.0121 loss_objectness: 0.0007 loss_rpn_box_reg: 0.0024 \n",
      "1100/1713 - loss_classifier: 0.0057 loss_box_reg: 0.0089 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0025 \n",
      "1200/1713 - loss_classifier: 0.0063 loss_box_reg: 0.0109 loss_objectness: 0.0009 loss_rpn_box_reg: 0.0023 \n",
      "1300/1713 - loss_classifier: 0.0056 loss_box_reg: 0.0108 loss_objectness: 0.0003 loss_rpn_box_reg: 0.0022 \n",
      "1400/1713 - loss_classifier: 0.0145 loss_box_reg: 0.0283 loss_objectness: 0.0003 loss_rpn_box_reg: 0.0012 \n",
      "1500/1713 - loss_classifier: 0.0049 loss_box_reg: 0.0068 loss_objectness: 0.0005 loss_rpn_box_reg: 0.0026 \n",
      "1600/1713 - loss_classifier: 0.0062 loss_box_reg: 0.0124 loss_objectness: 0.0005 loss_rpn_box_reg: 0.0023 \n",
      "1700/1713 - loss_classifier: 0.0053 loss_box_reg: 0.0147 loss_objectness: 0.0003 loss_rpn_box_reg: 0.0015 \n",
      "epoch:25/50 - Train Loss:0.0288, Val Loss:0.0278\n",
      "========== 831.966070652008 ==========\n",
      "100/1713 - loss_classifier: 0.0063 loss_box_reg: 0.0117 loss_objectness: 0.0001 loss_rpn_box_reg: 0.0017 \n",
      "200/1713 - loss_classifier: 0.0103 loss_box_reg: 0.0196 loss_objectness: 0.0005 loss_rpn_box_reg: 0.0010 \n",
      "300/1713 - loss_classifier: 0.0078 loss_box_reg: 0.0196 loss_objectness: 0.0006 loss_rpn_box_reg: 0.0024 \n",
      "400/1713 - loss_classifier: 0.0099 loss_box_reg: 0.0206 loss_objectness: 0.0003 loss_rpn_box_reg: 0.0014 \n",
      "500/1713 - loss_classifier: 0.0168 loss_box_reg: 0.0377 loss_objectness: 0.0020 loss_rpn_box_reg: 0.0040 \n",
      "600/1713 - loss_classifier: 0.0056 loss_box_reg: 0.0094 loss_objectness: 0.0005 loss_rpn_box_reg: 0.0019 \n",
      "700/1713 - loss_classifier: 0.0050 loss_box_reg: 0.0077 loss_objectness: 0.0018 loss_rpn_box_reg: 0.0015 \n",
      "800/1713 - loss_classifier: 0.0067 loss_box_reg: 0.0145 loss_objectness: 0.0046 loss_rpn_box_reg: 0.0174 \n",
      "900/1713 - loss_classifier: 0.0054 loss_box_reg: 0.0108 loss_objectness: 0.0003 loss_rpn_box_reg: 0.0013 \n",
      "1000/1713 - loss_classifier: 0.0076 loss_box_reg: 0.0098 loss_objectness: 0.0010 loss_rpn_box_reg: 0.0020 \n",
      "1100/1713 - loss_classifier: 0.0081 loss_box_reg: 0.0166 loss_objectness: 0.0004 loss_rpn_box_reg: 0.0018 \n",
      "1200/1713 - loss_classifier: 0.0143 loss_box_reg: 0.0252 loss_objectness: 0.0001 loss_rpn_box_reg: 0.0013 \n",
      "1300/1713 - loss_classifier: 0.0051 loss_box_reg: 0.0051 loss_objectness: 0.0019 loss_rpn_box_reg: 0.0032 \n",
      "1400/1713 - loss_classifier: 0.0032 loss_box_reg: 0.0090 loss_objectness: 0.0007 loss_rpn_box_reg: 0.0048 \n",
      "1500/1713 - loss_classifier: 0.0096 loss_box_reg: 0.0110 loss_objectness: 0.0003 loss_rpn_box_reg: 0.0016 \n",
      "1600/1713 - loss_classifier: 0.0070 loss_box_reg: 0.0092 loss_objectness: 0.0004 loss_rpn_box_reg: 0.0014 \n",
      "1700/1713 - loss_classifier: 0.0039 loss_box_reg: 0.0070 loss_objectness: 0.0007 loss_rpn_box_reg: 0.0031 \n",
      "epoch:26/50 - Train Loss:0.0281, Val Loss:0.0275\n",
      "========== 832.7380709648132 ==========\n",
      "100/1713 - loss_classifier: 0.0106 loss_box_reg: 0.0168 loss_objectness: 0.0004 loss_rpn_box_reg: 0.0030 \n",
      "200/1713 - loss_classifier: 0.0123 loss_box_reg: 0.0199 loss_objectness: 0.0010 loss_rpn_box_reg: 0.0020 \n",
      "300/1713 - loss_classifier: 0.0131 loss_box_reg: 0.0226 loss_objectness: 0.0015 loss_rpn_box_reg: 0.0118 \n",
      "400/1713 - loss_classifier: 0.0141 loss_box_reg: 0.0309 loss_objectness: 0.0013 loss_rpn_box_reg: 0.0018 \n",
      "500/1713 - loss_classifier: 0.0143 loss_box_reg: 0.0205 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0030 \n",
      "600/1713 - loss_classifier: 0.0127 loss_box_reg: 0.0197 loss_objectness: 0.0007 loss_rpn_box_reg: 0.0018 \n",
      "700/1713 - loss_classifier: 0.0060 loss_box_reg: 0.0127 loss_objectness: 0.0039 loss_rpn_box_reg: 0.0067 \n",
      "800/1713 - loss_classifier: 0.0116 loss_box_reg: 0.0195 loss_objectness: 0.0007 loss_rpn_box_reg: 0.0035 \n",
      "900/1713 - loss_classifier: 0.0106 loss_box_reg: 0.0332 loss_objectness: 0.0009 loss_rpn_box_reg: 0.0027 \n",
      "1000/1713 - loss_classifier: 0.0049 loss_box_reg: 0.0109 loss_objectness: 0.0032 loss_rpn_box_reg: 0.0015 \n",
      "1100/1713 - loss_classifier: 0.0050 loss_box_reg: 0.0048 loss_objectness: 0.0007 loss_rpn_box_reg: 0.0024 \n",
      "1200/1713 - loss_classifier: 0.0067 loss_box_reg: 0.0087 loss_objectness: 0.0006 loss_rpn_box_reg: 0.0013 \n",
      "1300/1713 - loss_classifier: 0.0041 loss_box_reg: 0.0089 loss_objectness: 0.0004 loss_rpn_box_reg: 0.0022 \n",
      "1400/1713 - loss_classifier: 0.0061 loss_box_reg: 0.0082 loss_objectness: 0.0003 loss_rpn_box_reg: 0.0026 \n",
      "1500/1713 - loss_classifier: 0.0056 loss_box_reg: 0.0177 loss_objectness: 0.0018 loss_rpn_box_reg: 0.0038 \n",
      "1600/1713 - loss_classifier: 0.0049 loss_box_reg: 0.0126 loss_objectness: 0.0001 loss_rpn_box_reg: 0.0033 \n",
      "1700/1713 - loss_classifier: 0.0017 loss_box_reg: 0.0018 loss_objectness: 0.0006 loss_rpn_box_reg: 0.0022 \n",
      "epoch:27/50 - Train Loss:0.0273, Val Loss:0.0258\n",
      "========== 830.8064057826996 ==========\n",
      "100/1713 - loss_classifier: 0.0285 loss_box_reg: 0.0441 loss_objectness: 0.0004 loss_rpn_box_reg: 0.0031 \n",
      "200/1713 - loss_classifier: 0.0090 loss_box_reg: 0.0177 loss_objectness: 0.0001 loss_rpn_box_reg: 0.0062 \n",
      "300/1713 - loss_classifier: 0.0079 loss_box_reg: 0.0108 loss_objectness: 0.0015 loss_rpn_box_reg: 0.0022 \n",
      "400/1713 - loss_classifier: 0.0073 loss_box_reg: 0.0149 loss_objectness: 0.0027 loss_rpn_box_reg: 0.0035 \n",
      "500/1713 - loss_classifier: 0.0039 loss_box_reg: 0.0140 loss_objectness: 0.0030 loss_rpn_box_reg: 0.0030 \n",
      "600/1713 - loss_classifier: 0.0010 loss_box_reg: 0.0012 loss_objectness: 0.0014 loss_rpn_box_reg: 0.0086 \n",
      "700/1713 - loss_classifier: 0.0028 loss_box_reg: 0.0052 loss_objectness: 0.0007 loss_rpn_box_reg: 0.0011 \n",
      "800/1713 - loss_classifier: 0.0064 loss_box_reg: 0.0178 loss_objectness: 0.0035 loss_rpn_box_reg: 0.0038 \n",
      "900/1713 - loss_classifier: 0.0050 loss_box_reg: 0.0051 loss_objectness: 0.0021 loss_rpn_box_reg: 0.0034 \n",
      "1000/1713 - loss_classifier: 0.0040 loss_box_reg: 0.0060 loss_objectness: 0.0021 loss_rpn_box_reg: 0.0026 \n",
      "1100/1713 - loss_classifier: 0.0098 loss_box_reg: 0.0144 loss_objectness: 0.0006 loss_rpn_box_reg: 0.0031 \n",
      "1200/1713 - loss_classifier: 0.0074 loss_box_reg: 0.0101 loss_objectness: 0.0004 loss_rpn_box_reg: 0.0056 \n",
      "1300/1713 - loss_classifier: 0.0149 loss_box_reg: 0.0315 loss_objectness: 0.0004 loss_rpn_box_reg: 0.0031 \n",
      "1400/1713 - loss_classifier: 0.0045 loss_box_reg: 0.0104 loss_objectness: 0.0030 loss_rpn_box_reg: 0.0032 \n",
      "1500/1713 - loss_classifier: 0.0074 loss_box_reg: 0.0116 loss_objectness: 0.0010 loss_rpn_box_reg: 0.0021 \n",
      "1600/1713 - loss_classifier: 0.0047 loss_box_reg: 0.0047 loss_objectness: 0.0001 loss_rpn_box_reg: 0.0017 \n",
      "1700/1713 - loss_classifier: 0.0028 loss_box_reg: 0.0057 loss_objectness: 0.0053 loss_rpn_box_reg: 0.0053 \n",
      "epoch:28/50 - Train Loss:0.0264, Val Loss:0.0254\n",
      "========== 832.0292913913727 ==========\n",
      "100/1713 - loss_classifier: 0.0055 loss_box_reg: 0.0079 loss_objectness: 0.0005 loss_rpn_box_reg: 0.0023 \n",
      "200/1713 - loss_classifier: 0.0051 loss_box_reg: 0.0062 loss_objectness: 0.0016 loss_rpn_box_reg: 0.0054 \n",
      "300/1713 - loss_classifier: 0.0022 loss_box_reg: 0.0047 loss_objectness: 0.0004 loss_rpn_box_reg: 0.0019 \n",
      "400/1713 - loss_classifier: 0.0070 loss_box_reg: 0.0114 loss_objectness: 0.0003 loss_rpn_box_reg: 0.0018 \n",
      "500/1713 - loss_classifier: 0.0072 loss_box_reg: 0.0174 loss_objectness: 0.0028 loss_rpn_box_reg: 0.0012 \n",
      "600/1713 - loss_classifier: 0.0055 loss_box_reg: 0.0100 loss_objectness: 0.0004 loss_rpn_box_reg: 0.0020 \n",
      "700/1713 - loss_classifier: 0.0132 loss_box_reg: 0.0261 loss_objectness: 0.0009 loss_rpn_box_reg: 0.0021 \n",
      "800/1713 - loss_classifier: 0.0095 loss_box_reg: 0.0155 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0021 \n",
      "900/1713 - loss_classifier: 0.0036 loss_box_reg: 0.0101 loss_objectness: 0.0003 loss_rpn_box_reg: 0.0011 \n",
      "1000/1713 - loss_classifier: 0.0007 loss_box_reg: 0.0035 loss_objectness: 0.0038 loss_rpn_box_reg: 0.0047 \n",
      "1100/1713 - loss_classifier: 0.0036 loss_box_reg: 0.0050 loss_objectness: 0.0004 loss_rpn_box_reg: 0.0022 \n",
      "1200/1713 - loss_classifier: 0.0018 loss_box_reg: 0.0023 loss_objectness: 0.0005 loss_rpn_box_reg: 0.0028 \n",
      "1300/1713 - loss_classifier: 0.0403 loss_box_reg: 0.0609 loss_objectness: 0.0010 loss_rpn_box_reg: 0.0134 \n",
      "1400/1713 - loss_classifier: 0.0091 loss_box_reg: 0.0218 loss_objectness: 0.0003 loss_rpn_box_reg: 0.0026 \n",
      "1500/1713 - loss_classifier: 0.0128 loss_box_reg: 0.0264 loss_objectness: 0.0003 loss_rpn_box_reg: 0.0028 \n",
      "1600/1713 - loss_classifier: 0.0081 loss_box_reg: 0.0139 loss_objectness: 0.0004 loss_rpn_box_reg: 0.0026 \n",
      "1700/1713 - loss_classifier: 0.0036 loss_box_reg: 0.0063 loss_objectness: 0.0052 loss_rpn_box_reg: 0.0069 \n",
      "epoch:29/50 - Train Loss:0.0256, Val Loss:0.0249\n",
      "========== 835.7607357501984 ==========\n",
      "100/1713 - loss_classifier: 0.0060 loss_box_reg: 0.0095 loss_objectness: 0.0005 loss_rpn_box_reg: 0.0025 \n",
      "200/1713 - loss_classifier: 0.0051 loss_box_reg: 0.0081 loss_objectness: 0.0007 loss_rpn_box_reg: 0.0010 \n",
      "300/1713 - loss_classifier: 0.0061 loss_box_reg: 0.0103 loss_objectness: 0.0020 loss_rpn_box_reg: 0.0050 \n",
      "400/1713 - loss_classifier: 0.0041 loss_box_reg: 0.0094 loss_objectness: 0.0007 loss_rpn_box_reg: 0.0026 \n",
      "500/1713 - loss_classifier: 0.0016 loss_box_reg: 0.0000 loss_objectness: 0.0033 loss_rpn_box_reg: 0.0038 \n",
      "600/1713 - loss_classifier: 0.0025 loss_box_reg: 0.0070 loss_objectness: 0.0047 loss_rpn_box_reg: 0.0019 \n",
      "700/1713 - loss_classifier: 0.0099 loss_box_reg: 0.0173 loss_objectness: 0.0035 loss_rpn_box_reg: 0.0076 \n",
      "800/1713 - loss_classifier: 0.0102 loss_box_reg: 0.0201 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0035 \n",
      "900/1713 - loss_classifier: 0.0074 loss_box_reg: 0.0091 loss_objectness: 0.0034 loss_rpn_box_reg: 0.0027 \n",
      "1000/1713 - loss_classifier: 0.0070 loss_box_reg: 0.0194 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0018 \n",
      "1100/1713 - loss_classifier: 0.0016 loss_box_reg: 0.0010 loss_objectness: 0.0010 loss_rpn_box_reg: 0.0049 \n",
      "1200/1713 - loss_classifier: 0.0156 loss_box_reg: 0.0238 loss_objectness: 0.0010 loss_rpn_box_reg: 0.0046 \n",
      "1300/1713 - loss_classifier: 0.0061 loss_box_reg: 0.0150 loss_objectness: 0.0001 loss_rpn_box_reg: 0.0016 \n",
      "1400/1713 - loss_classifier: 0.0125 loss_box_reg: 0.0261 loss_objectness: 0.0005 loss_rpn_box_reg: 0.0030 \n",
      "1500/1713 - loss_classifier: 0.0049 loss_box_reg: 0.0183 loss_objectness: 0.0005 loss_rpn_box_reg: 0.0086 \n",
      "1600/1713 - loss_classifier: 0.0112 loss_box_reg: 0.0135 loss_objectness: 0.0001 loss_rpn_box_reg: 0.0029 \n",
      "1700/1713 - loss_classifier: 0.0049 loss_box_reg: 0.0134 loss_objectness: 0.0008 loss_rpn_box_reg: 0.0036 \n",
      "epoch:30/50 - Train Loss:0.0250, Val Loss:0.0239\n",
      "========== 832.7351205348969 ==========\n",
      "========== 25090.93944954872 ==========\n",
      "100/1713 - loss_classifier: 0.0171 loss_box_reg: 0.0157 loss_objectness: 0.0009 loss_rpn_box_reg: 0.0042 \n",
      "200/1713 - loss_classifier: 0.0045 loss_box_reg: 0.0051 loss_objectness: 0.0010 loss_rpn_box_reg: 0.0012 \n",
      "300/1713 - loss_classifier: 0.0030 loss_box_reg: 0.0018 loss_objectness: 0.0009 loss_rpn_box_reg: 0.0064 \n",
      "400/1713 - loss_classifier: 0.0104 loss_box_reg: 0.0259 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0048 \n",
      "500/1713 - loss_classifier: 0.0095 loss_box_reg: 0.0256 loss_objectness: 0.0003 loss_rpn_box_reg: 0.0056 \n",
      "600/1713 - loss_classifier: 0.0058 loss_box_reg: 0.0127 loss_objectness: 0.0014 loss_rpn_box_reg: 0.0027 \n",
      "700/1713 - loss_classifier: 0.0068 loss_box_reg: 0.0140 loss_objectness: 0.0033 loss_rpn_box_reg: 0.0025 \n",
      "800/1713 - loss_classifier: 0.0119 loss_box_reg: 0.0166 loss_objectness: 0.0041 loss_rpn_box_reg: 0.0057 \n",
      "900/1713 - loss_classifier: 0.0076 loss_box_reg: 0.0141 loss_objectness: 0.0009 loss_rpn_box_reg: 0.0039 \n",
      "1000/1713 - loss_classifier: 0.0019 loss_box_reg: 0.0033 loss_objectness: 0.0001 loss_rpn_box_reg: 0.0014 \n",
      "1100/1713 - loss_classifier: 0.0086 loss_box_reg: 0.0183 loss_objectness: 0.0004 loss_rpn_box_reg: 0.0025 \n",
      "1200/1713 - loss_classifier: 0.0034 loss_box_reg: 0.0065 loss_objectness: 0.0037 loss_rpn_box_reg: 0.0033 \n",
      "1300/1713 - loss_classifier: 0.0093 loss_box_reg: 0.0137 loss_objectness: 0.0004 loss_rpn_box_reg: 0.0078 \n",
      "1400/1713 - loss_classifier: 0.0114 loss_box_reg: 0.0195 loss_objectness: 0.0026 loss_rpn_box_reg: 0.0051 \n",
      "1500/1713 - loss_classifier: 0.0507 loss_box_reg: 0.0897 loss_objectness: 0.0066 loss_rpn_box_reg: 0.0291 \n",
      "1600/1713 - loss_classifier: 0.0043 loss_box_reg: 0.0119 loss_objectness: 0.0007 loss_rpn_box_reg: 0.0023 \n",
      "1700/1713 - loss_classifier: 0.0024 loss_box_reg: 0.0057 loss_objectness: 0.0005 loss_rpn_box_reg: 0.0025 \n",
      "epoch:31/50 - Train Loss:0.0242, Val Loss:0.0232\n",
      "========== 829.8751091957092 ==========\n",
      "100/1713 - loss_classifier: 0.0078 loss_box_reg: 0.0104 loss_objectness: 0.0010 loss_rpn_box_reg: 0.0017 \n",
      "200/1713 - loss_classifier: 0.0056 loss_box_reg: 0.0073 loss_objectness: 0.0022 loss_rpn_box_reg: 0.0030 \n",
      "300/1713 - loss_classifier: 0.0046 loss_box_reg: 0.0085 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0014 \n",
      "400/1713 - loss_classifier: 0.0082 loss_box_reg: 0.0109 loss_objectness: 0.0009 loss_rpn_box_reg: 0.0037 \n",
      "500/1713 - loss_classifier: 0.0120 loss_box_reg: 0.0233 loss_objectness: 0.0007 loss_rpn_box_reg: 0.0022 \n",
      "600/1713 - loss_classifier: 0.0020 loss_box_reg: 0.0054 loss_objectness: 0.0098 loss_rpn_box_reg: 0.0024 \n",
      "700/1713 - loss_classifier: 0.0040 loss_box_reg: 0.0052 loss_objectness: 0.0051 loss_rpn_box_reg: 0.0038 \n",
      "800/1713 - loss_classifier: 0.0069 loss_box_reg: 0.0091 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0019 \n",
      "900/1713 - loss_classifier: 0.0050 loss_box_reg: 0.0063 loss_objectness: 0.0021 loss_rpn_box_reg: 0.0020 \n",
      "1000/1713 - loss_classifier: 0.0071 loss_box_reg: 0.0123 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0016 \n",
      "1100/1713 - loss_classifier: 0.0064 loss_box_reg: 0.0148 loss_objectness: 0.0004 loss_rpn_box_reg: 0.0047 \n",
      "1200/1713 - loss_classifier: 0.0069 loss_box_reg: 0.0131 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0017 \n",
      "1300/1713 - loss_classifier: 0.0056 loss_box_reg: 0.0121 loss_objectness: 0.0009 loss_rpn_box_reg: 0.0033 \n",
      "1400/1713 - loss_classifier: 0.0116 loss_box_reg: 0.0182 loss_objectness: 0.0004 loss_rpn_box_reg: 0.0031 \n",
      "1500/1713 - loss_classifier: 0.0139 loss_box_reg: 0.0243 loss_objectness: 0.0004 loss_rpn_box_reg: 0.0036 \n",
      "1600/1713 - loss_classifier: 0.0060 loss_box_reg: 0.0110 loss_objectness: 0.0001 loss_rpn_box_reg: 0.0032 \n",
      "1700/1713 - loss_classifier: 0.0053 loss_box_reg: 0.0069 loss_objectness: 0.0009 loss_rpn_box_reg: 0.0039 \n",
      "epoch:32/50 - Train Loss:0.0234, Val Loss:0.0231\n",
      "========== 829.2264885902405 ==========\n",
      "100/1713 - loss_classifier: 0.0049 loss_box_reg: 0.0089 loss_objectness: 0.0022 loss_rpn_box_reg: 0.0021 \n",
      "200/1713 - loss_classifier: 0.0039 loss_box_reg: 0.0126 loss_objectness: 0.0010 loss_rpn_box_reg: 0.0037 \n",
      "300/1713 - loss_classifier: 0.0068 loss_box_reg: 0.0098 loss_objectness: 0.0007 loss_rpn_box_reg: 0.0052 \n",
      "400/1713 - loss_classifier: 0.0065 loss_box_reg: 0.0131 loss_objectness: 0.0001 loss_rpn_box_reg: 0.0022 \n",
      "500/1713 - loss_classifier: 0.0059 loss_box_reg: 0.0116 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0018 \n",
      "600/1713 - loss_classifier: 0.0085 loss_box_reg: 0.0135 loss_objectness: 0.0006 loss_rpn_box_reg: 0.0023 \n",
      "700/1713 - loss_classifier: 0.0033 loss_box_reg: 0.0045 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0043 \n",
      "800/1713 - loss_classifier: 0.0085 loss_box_reg: 0.0099 loss_objectness: 0.0000 loss_rpn_box_reg: 0.0016 \n",
      "900/1713 - loss_classifier: 0.0128 loss_box_reg: 0.0175 loss_objectness: 0.0006 loss_rpn_box_reg: 0.0043 \n",
      "1000/1713 - loss_classifier: 0.0011 loss_box_reg: 0.0027 loss_objectness: 0.0003 loss_rpn_box_reg: 0.0036 \n",
      "1100/1713 - loss_classifier: 0.0053 loss_box_reg: 0.0068 loss_objectness: 0.0007 loss_rpn_box_reg: 0.0017 \n",
      "1200/1713 - loss_classifier: 0.0156 loss_box_reg: 0.0295 loss_objectness: 0.0008 loss_rpn_box_reg: 0.0046 \n",
      "1300/1713 - loss_classifier: 0.0067 loss_box_reg: 0.0131 loss_objectness: 0.0025 loss_rpn_box_reg: 0.0020 \n",
      "1400/1713 - loss_classifier: 0.0064 loss_box_reg: 0.0068 loss_objectness: 0.0003 loss_rpn_box_reg: 0.0029 \n",
      "1500/1713 - loss_classifier: 0.0036 loss_box_reg: 0.0078 loss_objectness: 0.0001 loss_rpn_box_reg: 0.0010 \n",
      "1600/1713 - loss_classifier: 0.0129 loss_box_reg: 0.0138 loss_objectness: 0.0018 loss_rpn_box_reg: 0.0040 \n",
      "1700/1713 - loss_classifier: 0.0073 loss_box_reg: 0.0084 loss_objectness: 0.0006 loss_rpn_box_reg: 0.0059 \n",
      "epoch:33/50 - Train Loss:0.0227, Val Loss:0.0217\n",
      "========== 829.7497406005859 ==========\n",
      "100/1713 - loss_classifier: 0.0094 loss_box_reg: 0.0250 loss_objectness: 0.0006 loss_rpn_box_reg: 0.0052 \n",
      "200/1713 - loss_classifier: 0.0177 loss_box_reg: 0.0225 loss_objectness: 0.0013 loss_rpn_box_reg: 0.0021 \n",
      "300/1713 - loss_classifier: 0.0047 loss_box_reg: 0.0087 loss_objectness: 0.0006 loss_rpn_box_reg: 0.0045 \n",
      "400/1713 - loss_classifier: 0.0045 loss_box_reg: 0.0079 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0015 \n",
      "500/1713 - loss_classifier: 0.0422 loss_box_reg: 0.0652 loss_objectness: 0.0032 loss_rpn_box_reg: 0.0112 \n",
      "600/1713 - loss_classifier: 0.0022 loss_box_reg: 0.0047 loss_objectness: 0.0007 loss_rpn_box_reg: 0.0053 \n",
      "700/1713 - loss_classifier: 0.0046 loss_box_reg: 0.0101 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0010 \n",
      "800/1713 - loss_classifier: 0.0041 loss_box_reg: 0.0084 loss_objectness: 0.0004 loss_rpn_box_reg: 0.0042 \n",
      "900/1713 - loss_classifier: 0.0115 loss_box_reg: 0.0238 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0030 \n",
      "1000/1713 - loss_classifier: 0.0028 loss_box_reg: 0.0061 loss_objectness: 0.0006 loss_rpn_box_reg: 0.0014 \n",
      "1100/1713 - loss_classifier: 0.0090 loss_box_reg: 0.0207 loss_objectness: 0.0019 loss_rpn_box_reg: 0.0033 \n",
      "1200/1713 - loss_classifier: 0.0104 loss_box_reg: 0.0196 loss_objectness: 0.0004 loss_rpn_box_reg: 0.0028 \n",
      "1300/1713 - loss_classifier: 0.0119 loss_box_reg: 0.0231 loss_objectness: 0.0001 loss_rpn_box_reg: 0.0033 \n",
      "1400/1713 - loss_classifier: 0.0019 loss_box_reg: 0.0035 loss_objectness: 0.0016 loss_rpn_box_reg: 0.0101 \n",
      "1500/1713 - loss_classifier: 0.0059 loss_box_reg: 0.0063 loss_objectness: 0.0004 loss_rpn_box_reg: 0.0019 \n",
      "1600/1713 - loss_classifier: 0.0113 loss_box_reg: 0.0271 loss_objectness: 0.0009 loss_rpn_box_reg: 0.0033 \n",
      "1700/1713 - loss_classifier: 0.0042 loss_box_reg: 0.0054 loss_objectness: 0.0015 loss_rpn_box_reg: 0.0009 \n",
      "epoch:34/50 - Train Loss:0.0221, Val Loss:0.0213\n",
      "========== 830.0808579921722 ==========\n",
      "100/1713 - loss_classifier: 0.0022 loss_box_reg: 0.0048 loss_objectness: 0.0006 loss_rpn_box_reg: 0.0046 \n",
      "200/1713 - loss_classifier: 0.0083 loss_box_reg: 0.0168 loss_objectness: 0.0041 loss_rpn_box_reg: 0.0121 \n",
      "300/1713 - loss_classifier: 0.0088 loss_box_reg: 0.0155 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0029 \n",
      "400/1713 - loss_classifier: 0.0025 loss_box_reg: 0.0045 loss_objectness: 0.0009 loss_rpn_box_reg: 0.0013 \n",
      "500/1713 - loss_classifier: 0.0064 loss_box_reg: 0.0149 loss_objectness: 0.0003 loss_rpn_box_reg: 0.0028 \n",
      "600/1713 - loss_classifier: 0.0035 loss_box_reg: 0.0085 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0009 \n",
      "700/1713 - loss_classifier: 0.0204 loss_box_reg: 0.0378 loss_objectness: 0.0006 loss_rpn_box_reg: 0.0045 \n",
      "800/1713 - loss_classifier: 0.0051 loss_box_reg: 0.0124 loss_objectness: 0.0013 loss_rpn_box_reg: 0.0031 \n",
      "900/1713 - loss_classifier: 0.0038 loss_box_reg: 0.0064 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0034 \n",
      "1000/1713 - loss_classifier: 0.0044 loss_box_reg: 0.0071 loss_objectness: 0.0003 loss_rpn_box_reg: 0.0012 \n",
      "1100/1713 - loss_classifier: 0.0033 loss_box_reg: 0.0070 loss_objectness: 0.0001 loss_rpn_box_reg: 0.0022 \n",
      "1200/1713 - loss_classifier: 0.0034 loss_box_reg: 0.0078 loss_objectness: 0.0005 loss_rpn_box_reg: 0.0023 \n",
      "1300/1713 - loss_classifier: 0.0138 loss_box_reg: 0.0280 loss_objectness: 0.0008 loss_rpn_box_reg: 0.0065 \n",
      "1400/1713 - loss_classifier: 0.0045 loss_box_reg: 0.0081 loss_objectness: 0.0006 loss_rpn_box_reg: 0.0015 \n",
      "1500/1713 - loss_classifier: 0.0061 loss_box_reg: 0.0110 loss_objectness: 0.0008 loss_rpn_box_reg: 0.0039 \n",
      "1600/1713 - loss_classifier: 0.0018 loss_box_reg: 0.0052 loss_objectness: 0.0007 loss_rpn_box_reg: 0.0017 \n",
      "1700/1713 - loss_classifier: 0.0095 loss_box_reg: 0.0202 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0023 \n",
      "epoch:35/50 - Train Loss:0.0216, Val Loss:0.0212\n",
      "========== 830.0373156070709 ==========\n",
      "100/1713 - loss_classifier: 0.0121 loss_box_reg: 0.0208 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0020 \n",
      "200/1713 - loss_classifier: 0.0243 loss_box_reg: 0.0457 loss_objectness: 0.0040 loss_rpn_box_reg: 0.0107 \n",
      "300/1713 - loss_classifier: 0.0073 loss_box_reg: 0.0104 loss_objectness: 0.0001 loss_rpn_box_reg: 0.0016 \n",
      "400/1713 - loss_classifier: 0.0050 loss_box_reg: 0.0119 loss_objectness: 0.0005 loss_rpn_box_reg: 0.0026 \n",
      "500/1713 - loss_classifier: 0.0048 loss_box_reg: 0.0077 loss_objectness: 0.0001 loss_rpn_box_reg: 0.0028 \n",
      "600/1713 - loss_classifier: 0.0036 loss_box_reg: 0.0055 loss_objectness: 0.0004 loss_rpn_box_reg: 0.0037 \n",
      "700/1713 - loss_classifier: 0.0125 loss_box_reg: 0.0212 loss_objectness: 0.0009 loss_rpn_box_reg: 0.0034 \n",
      "800/1713 - loss_classifier: 0.0032 loss_box_reg: 0.0078 loss_objectness: 0.0003 loss_rpn_box_reg: 0.0008 \n",
      "900/1713 - loss_classifier: 0.0067 loss_box_reg: 0.0140 loss_objectness: 0.0001 loss_rpn_box_reg: 0.0018 \n",
      "1000/1713 - loss_classifier: 0.0083 loss_box_reg: 0.0301 loss_objectness: 0.0008 loss_rpn_box_reg: 0.0052 \n",
      "1100/1713 - loss_classifier: 0.0069 loss_box_reg: 0.0145 loss_objectness: 0.0011 loss_rpn_box_reg: 0.0035 \n",
      "1200/1713 - loss_classifier: 0.0040 loss_box_reg: 0.0064 loss_objectness: 0.0042 loss_rpn_box_reg: 0.0030 \n",
      "1300/1713 - loss_classifier: 0.0018 loss_box_reg: 0.0072 loss_objectness: 0.0031 loss_rpn_box_reg: 0.0092 \n",
      "1400/1713 - loss_classifier: 0.0040 loss_box_reg: 0.0047 loss_objectness: 0.0007 loss_rpn_box_reg: 0.0021 \n",
      "1500/1713 - loss_classifier: 0.0045 loss_box_reg: 0.0094 loss_objectness: 0.0006 loss_rpn_box_reg: 0.0028 \n",
      "1600/1713 - loss_classifier: 0.0076 loss_box_reg: 0.0136 loss_objectness: 0.0019 loss_rpn_box_reg: 0.0043 \n",
      "1700/1713 - loss_classifier: 0.0100 loss_box_reg: 0.0163 loss_objectness: 0.0016 loss_rpn_box_reg: 0.0040 \n",
      "epoch:36/50 - Train Loss:0.0212, Val Loss:0.0206\n",
      "========== 832.7729635238647 ==========\n",
      "100/1713 - loss_classifier: 0.0030 loss_box_reg: 0.0082 loss_objectness: 0.0003 loss_rpn_box_reg: 0.0012 \n",
      "200/1713 - loss_classifier: 0.0118 loss_box_reg: 0.0234 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0029 \n",
      "300/1713 - loss_classifier: 0.0055 loss_box_reg: 0.0105 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0023 \n",
      "400/1713 - loss_classifier: 0.0032 loss_box_reg: 0.0055 loss_objectness: 0.0020 loss_rpn_box_reg: 0.0049 \n",
      "500/1713 - loss_classifier: 0.0071 loss_box_reg: 0.0115 loss_objectness: 0.0005 loss_rpn_box_reg: 0.0031 \n",
      "600/1713 - loss_classifier: 0.0038 loss_box_reg: 0.0070 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0017 \n",
      "700/1713 - loss_classifier: 0.0116 loss_box_reg: 0.0275 loss_objectness: 0.0039 loss_rpn_box_reg: 0.0027 \n",
      "800/1713 - loss_classifier: 0.0063 loss_box_reg: 0.0102 loss_objectness: 0.0000 loss_rpn_box_reg: 0.0016 \n",
      "900/1713 - loss_classifier: 0.0104 loss_box_reg: 0.0195 loss_objectness: 0.0017 loss_rpn_box_reg: 0.0033 \n",
      "1000/1713 - loss_classifier: 0.0150 loss_box_reg: 0.0315 loss_objectness: 0.0005 loss_rpn_box_reg: 0.0137 \n",
      "1100/1713 - loss_classifier: 0.0037 loss_box_reg: 0.0082 loss_objectness: 0.0003 loss_rpn_box_reg: 0.0020 \n",
      "1200/1713 - loss_classifier: 0.0041 loss_box_reg: 0.0084 loss_objectness: 0.0003 loss_rpn_box_reg: 0.0018 \n",
      "1300/1713 - loss_classifier: 0.0052 loss_box_reg: 0.0069 loss_objectness: 0.0005 loss_rpn_box_reg: 0.0022 \n",
      "1400/1713 - loss_classifier: 0.0109 loss_box_reg: 0.0253 loss_objectness: 0.0003 loss_rpn_box_reg: 0.0022 \n",
      "1500/1713 - loss_classifier: 0.0059 loss_box_reg: 0.0080 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0021 \n",
      "1600/1713 - loss_classifier: 0.0031 loss_box_reg: 0.0096 loss_objectness: 0.0010 loss_rpn_box_reg: 0.0023 \n",
      "1700/1713 - loss_classifier: 0.0150 loss_box_reg: 0.0109 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0047 \n",
      "epoch:37/50 - Train Loss:0.0207, Val Loss:0.0201\n",
      "========== 833.6576409339905 ==========\n",
      "100/1713 - loss_classifier: 0.0055 loss_box_reg: 0.0096 loss_objectness: 0.0094 loss_rpn_box_reg: 0.0032 \n",
      "200/1713 - loss_classifier: 0.0073 loss_box_reg: 0.0168 loss_objectness: 0.0027 loss_rpn_box_reg: 0.0023 \n",
      "300/1713 - loss_classifier: 0.0013 loss_box_reg: 0.0017 loss_objectness: 0.0001 loss_rpn_box_reg: 0.0012 \n",
      "400/1713 - loss_classifier: 0.0054 loss_box_reg: 0.0152 loss_objectness: 0.0008 loss_rpn_box_reg: 0.0027 \n",
      "500/1713 - loss_classifier: 0.0011 loss_box_reg: 0.0013 loss_objectness: 0.0010 loss_rpn_box_reg: 0.0034 \n",
      "600/1713 - loss_classifier: 0.0382 loss_box_reg: 0.0527 loss_objectness: 0.0028 loss_rpn_box_reg: 0.0094 \n",
      "700/1713 - loss_classifier: 0.0073 loss_box_reg: 0.0116 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0039 \n",
      "800/1713 - loss_classifier: 0.0050 loss_box_reg: 0.0083 loss_objectness: 0.0006 loss_rpn_box_reg: 0.0016 \n",
      "900/1713 - loss_classifier: 0.0022 loss_box_reg: 0.0051 loss_objectness: 0.0001 loss_rpn_box_reg: 0.0037 \n",
      "1000/1713 - loss_classifier: 0.0094 loss_box_reg: 0.0167 loss_objectness: 0.0005 loss_rpn_box_reg: 0.0031 \n",
      "1100/1713 - loss_classifier: 0.0036 loss_box_reg: 0.0106 loss_objectness: 0.0015 loss_rpn_box_reg: 0.0031 \n",
      "1200/1713 - loss_classifier: 0.0038 loss_box_reg: 0.0100 loss_objectness: 0.0003 loss_rpn_box_reg: 0.0013 \n",
      "1300/1713 - loss_classifier: 0.0026 loss_box_reg: 0.0048 loss_objectness: 0.0001 loss_rpn_box_reg: 0.0028 \n",
      "1400/1713 - loss_classifier: 0.0025 loss_box_reg: 0.0046 loss_objectness: 0.0005 loss_rpn_box_reg: 0.0022 \n",
      "1500/1713 - loss_classifier: 0.0054 loss_box_reg: 0.0082 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0017 \n",
      "1600/1713 - loss_classifier: 0.0062 loss_box_reg: 0.0078 loss_objectness: 0.0007 loss_rpn_box_reg: 0.0005 \n",
      "1700/1713 - loss_classifier: 0.0015 loss_box_reg: 0.0048 loss_objectness: 0.0013 loss_rpn_box_reg: 0.0043 \n",
      "epoch:38/50 - Train Loss:0.0202, Val Loss:0.0198\n",
      "========== 848.8613855838776 ==========\n",
      "100/1713 - loss_classifier: 0.0119 loss_box_reg: 0.0261 loss_objectness: 0.0018 loss_rpn_box_reg: 0.0019 \n",
      "200/1713 - loss_classifier: 0.0027 loss_box_reg: 0.0024 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0026 \n",
      "300/1713 - loss_classifier: 0.0035 loss_box_reg: 0.0080 loss_objectness: 0.0003 loss_rpn_box_reg: 0.0025 \n",
      "400/1713 - loss_classifier: 0.0032 loss_box_reg: 0.0047 loss_objectness: 0.0030 loss_rpn_box_reg: 0.0008 \n",
      "500/1713 - loss_classifier: 0.0085 loss_box_reg: 0.0085 loss_objectness: 0.0000 loss_rpn_box_reg: 0.0010 \n",
      "600/1713 - loss_classifier: 0.0018 loss_box_reg: 0.0034 loss_objectness: 0.0004 loss_rpn_box_reg: 0.0029 \n",
      "700/1713 - loss_classifier: 0.0083 loss_box_reg: 0.0183 loss_objectness: 0.0001 loss_rpn_box_reg: 0.0017 \n",
      "800/1713 - loss_classifier: 0.0048 loss_box_reg: 0.0070 loss_objectness: 0.0003 loss_rpn_box_reg: 0.0051 \n",
      "900/1713 - loss_classifier: 0.0101 loss_box_reg: 0.0228 loss_objectness: 0.0043 loss_rpn_box_reg: 0.0029 \n",
      "1000/1713 - loss_classifier: 0.0071 loss_box_reg: 0.0071 loss_objectness: 0.0011 loss_rpn_box_reg: 0.0015 \n",
      "1100/1713 - loss_classifier: 0.0031 loss_box_reg: 0.0058 loss_objectness: 0.0001 loss_rpn_box_reg: 0.0018 \n",
      "1200/1713 - loss_classifier: 0.0019 loss_box_reg: 0.0054 loss_objectness: 0.0013 loss_rpn_box_reg: 0.0027 \n",
      "1300/1713 - loss_classifier: 0.0035 loss_box_reg: 0.0036 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0018 \n",
      "1400/1713 - loss_classifier: 0.0049 loss_box_reg: 0.0069 loss_objectness: 0.0005 loss_rpn_box_reg: 0.0025 \n",
      "1500/1713 - loss_classifier: 0.0030 loss_box_reg: 0.0076 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0020 \n",
      "1600/1713 - loss_classifier: 0.0120 loss_box_reg: 0.0151 loss_objectness: 0.0009 loss_rpn_box_reg: 0.0011 \n",
      "1700/1713 - loss_classifier: 0.0046 loss_box_reg: 0.0080 loss_objectness: 0.0001 loss_rpn_box_reg: 0.0034 \n",
      "epoch:39/50 - Train Loss:0.0198, Val Loss:0.0193\n",
      "========== 896.5509767532349 ==========\n",
      "100/1713 - loss_classifier: 0.0065 loss_box_reg: 0.0144 loss_objectness: 0.0004 loss_rpn_box_reg: 0.0016 \n",
      "200/1713 - loss_classifier: 0.0074 loss_box_reg: 0.0168 loss_objectness: 0.0006 loss_rpn_box_reg: 0.0041 \n",
      "300/1713 - loss_classifier: 0.0069 loss_box_reg: 0.0149 loss_objectness: 0.0001 loss_rpn_box_reg: 0.0016 \n",
      "400/1713 - loss_classifier: 0.0075 loss_box_reg: 0.0095 loss_objectness: 0.0003 loss_rpn_box_reg: 0.0011 \n",
      "500/1713 - loss_classifier: 0.0082 loss_box_reg: 0.0219 loss_objectness: 0.0005 loss_rpn_box_reg: 0.0059 \n",
      "600/1713 - loss_classifier: 0.0057 loss_box_reg: 0.0061 loss_objectness: 0.0011 loss_rpn_box_reg: 0.0016 \n",
      "700/1713 - loss_classifier: 0.0113 loss_box_reg: 0.0107 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0014 \n",
      "800/1713 - loss_classifier: 0.0027 loss_box_reg: 0.0027 loss_objectness: 0.0006 loss_rpn_box_reg: 0.0027 \n",
      "900/1713 - loss_classifier: 0.0036 loss_box_reg: 0.0095 loss_objectness: 0.0004 loss_rpn_box_reg: 0.0043 \n",
      "1000/1713 - loss_classifier: 0.0128 loss_box_reg: 0.0195 loss_objectness: 0.0000 loss_rpn_box_reg: 0.0014 \n",
      "1100/1713 - loss_classifier: 0.0047 loss_box_reg: 0.0058 loss_objectness: 0.0001 loss_rpn_box_reg: 0.0017 \n",
      "1200/1713 - loss_classifier: 0.0073 loss_box_reg: 0.0078 loss_objectness: 0.0001 loss_rpn_box_reg: 0.0011 \n",
      "1300/1713 - loss_classifier: 0.0011 loss_box_reg: 0.0015 loss_objectness: 0.0003 loss_rpn_box_reg: 0.0040 \n",
      "1400/1713 - loss_classifier: 0.0093 loss_box_reg: 0.0163 loss_objectness: 0.0003 loss_rpn_box_reg: 0.0022 \n",
      "1500/1713 - loss_classifier: 0.0029 loss_box_reg: 0.0062 loss_objectness: 0.0019 loss_rpn_box_reg: 0.0034 \n",
      "1600/1713 - loss_classifier: 0.0079 loss_box_reg: 0.0123 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0027 \n",
      "1700/1713 - loss_classifier: 0.0068 loss_box_reg: 0.0121 loss_objectness: 0.0001 loss_rpn_box_reg: 0.0031 \n",
      "epoch:40/50 - Train Loss:0.0195, Val Loss:0.0188\n",
      "========== 894.7566208839417 ==========\n",
      "========== 33546.67944645882 ==========\n",
      "100/1713 - loss_classifier: 0.0065 loss_box_reg: 0.0157 loss_objectness: 0.0001 loss_rpn_box_reg: 0.0016 \n",
      "200/1713 - loss_classifier: 0.0117 loss_box_reg: 0.0249 loss_objectness: 0.0005 loss_rpn_box_reg: 0.0069 \n",
      "300/1713 - loss_classifier: 0.0097 loss_box_reg: 0.0196 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0010 \n",
      "400/1713 - loss_classifier: 0.0030 loss_box_reg: 0.0036 loss_objectness: 0.0018 loss_rpn_box_reg: 0.0051 \n",
      "500/1713 - loss_classifier: 0.0054 loss_box_reg: 0.0119 loss_objectness: 0.0023 loss_rpn_box_reg: 0.0020 \n",
      "600/1713 - loss_classifier: 0.0020 loss_box_reg: 0.0041 loss_objectness: 0.0007 loss_rpn_box_reg: 0.0034 \n",
      "700/1713 - loss_classifier: 0.0021 loss_box_reg: 0.0049 loss_objectness: 0.0008 loss_rpn_box_reg: 0.0022 \n",
      "800/1713 - loss_classifier: 0.0021 loss_box_reg: 0.0060 loss_objectness: 0.0007 loss_rpn_box_reg: 0.0056 \n",
      "900/1713 - loss_classifier: 0.0094 loss_box_reg: 0.0134 loss_objectness: 0.0008 loss_rpn_box_reg: 0.0007 \n",
      "1000/1713 - loss_classifier: 0.0038 loss_box_reg: 0.0129 loss_objectness: 0.0003 loss_rpn_box_reg: 0.0016 \n",
      "1100/1713 - loss_classifier: 0.0050 loss_box_reg: 0.0113 loss_objectness: 0.0013 loss_rpn_box_reg: 0.0016 \n",
      "1200/1713 - loss_classifier: 0.0092 loss_box_reg: 0.0133 loss_objectness: 0.0017 loss_rpn_box_reg: 0.0026 \n",
      "1300/1713 - loss_classifier: 0.0043 loss_box_reg: 0.0083 loss_objectness: 0.0018 loss_rpn_box_reg: 0.0035 \n",
      "1400/1713 - loss_classifier: 0.0055 loss_box_reg: 0.0115 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0017 \n",
      "1500/1713 - loss_classifier: 0.0044 loss_box_reg: 0.0041 loss_objectness: 0.0020 loss_rpn_box_reg: 0.0013 \n",
      "1600/1713 - loss_classifier: 0.0028 loss_box_reg: 0.0043 loss_objectness: 0.0012 loss_rpn_box_reg: 0.0064 \n",
      "1700/1713 - loss_classifier: 0.0063 loss_box_reg: 0.0171 loss_objectness: 0.0007 loss_rpn_box_reg: 0.0055 \n",
      "epoch:41/50 - Train Loss:0.0190, Val Loss:0.0181\n",
      "========== 889.951409816742 ==========\n",
      "100/1713 - loss_classifier: 0.0039 loss_box_reg: 0.0095 loss_objectness: 0.0009 loss_rpn_box_reg: 0.0033 \n",
      "200/1713 - loss_classifier: 0.0040 loss_box_reg: 0.0034 loss_objectness: 0.0040 loss_rpn_box_reg: 0.0014 \n",
      "300/1713 - loss_classifier: 0.0071 loss_box_reg: 0.0148 loss_objectness: 0.0005 loss_rpn_box_reg: 0.0047 \n",
      "400/1713 - loss_classifier: 0.0011 loss_box_reg: 0.0037 loss_objectness: 0.0007 loss_rpn_box_reg: 0.0027 \n",
      "500/1713 - loss_classifier: 0.0084 loss_box_reg: 0.0119 loss_objectness: 0.0004 loss_rpn_box_reg: 0.0043 \n",
      "600/1713 - loss_classifier: 0.0071 loss_box_reg: 0.0149 loss_objectness: 0.0011 loss_rpn_box_reg: 0.0024 \n",
      "700/1713 - loss_classifier: 0.0090 loss_box_reg: 0.0154 loss_objectness: 0.0008 loss_rpn_box_reg: 0.0026 \n",
      "800/1713 - loss_classifier: 0.0065 loss_box_reg: 0.0081 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0013 \n",
      "900/1713 - loss_classifier: 0.0045 loss_box_reg: 0.0032 loss_objectness: 0.0015 loss_rpn_box_reg: 0.0042 \n",
      "1000/1713 - loss_classifier: 0.0069 loss_box_reg: 0.0135 loss_objectness: 0.0012 loss_rpn_box_reg: 0.0047 \n",
      "1100/1713 - loss_classifier: 0.0011 loss_box_reg: 0.0028 loss_objectness: 0.0008 loss_rpn_box_reg: 0.0024 \n",
      "1200/1713 - loss_classifier: 0.0079 loss_box_reg: 0.0112 loss_objectness: 0.0001 loss_rpn_box_reg: 0.0035 \n",
      "1300/1713 - loss_classifier: 0.0067 loss_box_reg: 0.0110 loss_objectness: 0.0002 loss_rpn_box_reg: 0.0012 \n",
      "1400/1713 - loss_classifier: 0.0042 loss_box_reg: 0.0079 loss_objectness: 0.0001 loss_rpn_box_reg: 0.0017 \n",
      "1500/1713 - loss_classifier: 0.0088 loss_box_reg: 0.0142 loss_objectness: 0.0005 loss_rpn_box_reg: 0.0018 \n",
      "1600/1713 - loss_classifier: 0.0036 loss_box_reg: 0.0044 loss_objectness: 0.0005 loss_rpn_box_reg: 0.0036 \n",
      "1700/1713 - loss_classifier: 0.0049 loss_box_reg: 0.0064 loss_objectness: 0.0006 loss_rpn_box_reg: 0.0012 \n"
     ]
    }
   ],
   "source": [
    "# num_epochs = 1\n",
    "# train_losses = []\n",
    "# val_losses = []\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     train_loss, val_loss = train_one_epoch(dataloaders, model, optimizer, DEVICE)\n",
    "#     train_losses.append(train_loss)\n",
    "#     val_losses.append(val_loss)\n",
    "\n",
    "#     print(f\"epoch:{epoch+1}/{num_epochs} - Train Loss:{train_loss['total_loss']:.4f}, Val Loss:{val_loss['total_loss']:.4f}\")\n",
    "#     if(epoch+1) % 10 == 0:\n",
    "#         save_model(model.stat_dict(), f\"model_{epoch+1}.pth\")\n",
    "timelist = []\n",
    "\n",
    "num_epochs = 50\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "fstartTime = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    startTime = time.time()\n",
    "    train_loss, val_loss = train_one_epoch(dataloaders, model, optimizer, DEVICE)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    endTime = time.time()\n",
    "    print(f\"epoch:{epoch+1}/{num_epochs} - Train Loss:{train_loss['total_loss']:.4f}, Val Loss:{val_loss['total_loss']:.4f}\")\n",
    "    print('='*10, endTime - startTime, '='*10)\n",
    "    timelist.append(endTime - startTime)\n",
    "    if(epoch+1) % 10 == 0:\n",
    "        save_model(model.state_dict(), f\"model_{epoch+1}.pth\")\n",
    "        print('='*10, endTime - fstartTime, '='*10)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31b81c7-54df-4868-b5cb-df3617f47940",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_loss_classifier = []\n",
    "tr_loss_box_reg = []\n",
    "tr_loss_objectness = []\n",
    "tr_loss_rpn_box_reg = []\n",
    "tr_loss_total = []\n",
    "\n",
    "for tr_loss in train_losses:\n",
    "    tr_loss_classifier.append(tr_loss['loss_classifier'])\n",
    "    tr_loss_box_reg.append(tr_loss['loss_box_reg'])\n",
    "    tr_loss_objectness.append(tr_loss['loss_objectness'])\n",
    "    tr_loss_rpn_box_reg.append(tr_loss['loss_rpn_box_reg'])\n",
    "    tr_loss_total.append(tr_loss['total_loss'])\n",
    "\n",
    "val_loss_classifier = []\n",
    "val_loss_box_reg = []\n",
    "val_loss_objectness = []\n",
    "val_loss_rpn_box_reg = []\n",
    "val_loss_total = []\n",
    "\n",
    "for vl_loss in val_losses:\n",
    "    val_loss_classifier.append(vl_loss['loss_classifier'])\n",
    "    val_loss_box_reg.append(vl_loss['loss_box_reg'])\n",
    "    val_loss_objectness.append(vl_loss['loss_objectness'])\n",
    "    val_loss_rpn_box_reg.append(vl_loss['loss_rpn_box_reg'])\n",
    "    val_loss_total.append(vl_loss['total_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1774ce-ad12-4912-b103-ffcc7c20447d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(tr_loss_total, label=\"train_total_loss\")\n",
    "plt.plot(tr_loss_classifier, label=\"train_loss_classifier\")\n",
    "plt.plot(tr_loss_box_reg,  label=\"train_loss_box_reg\")\n",
    "plt.plot(tr_loss_objectness, label=\"train_loss_objectness\")\n",
    "plt.plot(tr_loss_rpn_box_reg,  label=\"train_loss_rpn_box_reg\")\n",
    "\n",
    "plt.plot(val_loss_total, label=\"val_total_loss\")\n",
    "plt.plot(val_loss_classifier, label=\"val_loss_classifier\")\n",
    "plt.plot(val_loss_box_reg,  label=\"val_loss_box_reg\")\n",
    "plt.plot(val_loss_objectness, label=\"val_loss_objectness\")\n",
    "plt.plot(val_loss_rpn_box_reg,  label=\"val_loss_rpn_box_reg\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.grid(\"on\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c46395e-26e6-4a5f-94ad-3d2237563b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
